{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import timeit\n",
    "import torch\n",
    "import numpy as np\n",
    "import ops\n",
    "from utils import lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ops' from '/Users/theissjd/Documents/Berkeley/code/rf_pool/rf_pool/ops.py'>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.local_softmax\n",
    "rf_u = torch.rand(1,10,16)\n",
    "mask = torch.zeros_like(rf_u)\n",
    "mask[:,:,:8] = 1.\n",
    "out0 = ops.local_softmax(rf_u, -1, mask)\n",
    "# manually apply softmax with mask\n",
    "mask = -1. * torch.exp(np.inf * (1. - 2. * mask))\n",
    "rf_u = torch.add(rf_u, mask)\n",
    "out1 = torch.softmax(rf_u, -1)\n",
    "assert torch.all(torch.eq(out0, out1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.prob_max_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.prob_max_pool(rf_u, out_shape)\n",
    "# manually perform prob_max_pool\n",
    "rf_u_0 = torch.cat([rf_u, torch.zeros(1,10,1)], -1)\n",
    "rf_u_0_softmax = torch.softmax(rf_u_0, -1)\n",
    "probs = torch.reshape(rf_u_0_softmax[:,:,:-1], out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=rf_u_0_softmax).sample()\n",
    "samples = torch.reshape(samples[:,:,:-1], out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(torch.reshape(1. - rf_u_0_softmax[:,:,-1], (1,10,1,1)), samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.stochastic_max_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.stochastic_max_pool(rf_u, out_shape)\n",
    "# manually perform prob_max_pool\n",
    "rf_u_softmax = torch.softmax(rf_u, -1)\n",
    "probs = torch.reshape(rf_u_softmax, out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=rf_u_softmax).sample()\n",
    "samples = torch.reshape(samples, out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(probs, samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.div_norm_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "n = 2.\n",
    "sigma = 0.5\n",
    "h_mean, h_sample, p_mean, p_sample = ops.div_norm_pool(rf_u, out_shape, n=n, sigma=sigma)\n",
    "# manually perform div_norm_pool\n",
    "rf_u_n = torch.pow(rf_u, n)\n",
    "sigma_n = torch.pow(torch.as_tensor(sigma, dtype=rf_u.dtype), n)\n",
    "probs = torch.div(rf_u_n, sigma_n + torch.sum(rf_u_n, dim=-1, keepdim=True))\n",
    "assert torch.all(torch.eq(h_mean, torch.reshape(probs, out_shape)))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=torch.softmax(probs, -1)).sample()\n",
    "assert torch.all(torch.eq(h_sample, torch.reshape(samples, out_shape)))\n",
    "p_probs = torch.reshape(torch.mul(probs, samples), out_shape)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = torch.reshape(samples, out_shape)\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.average_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "mask = None\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.average_pool(rf_u, out_shape, mask)\n",
    "# manually perform average_pool\n",
    "n_units = torch.as_tensor(rf_u.shape[-1], dtype=rf_u.dtype)\n",
    "if type(mask) is torch.Tensor:\n",
    "    n_units = torch.sum(mask, -1, keepdim=True)\n",
    "probs = torch.div(rf_u, n_units)\n",
    "assert torch.all(torch.eq(h_mean, torch.reshape(probs, out_shape)))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=ops.local_softmax(probs, -1, mask)).sample()\n",
    "assert torch.all(torch.eq(h_sample, torch.reshape(samples, out_shape)))\n",
    "p_probs = torch.mul(probs, samples)\n",
    "assert torch.all(torch.eq(p_mean, torch.reshape(p_probs, out_shape)))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, torch.reshape(p_samples, out_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.sum_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.sum_pool(rf_u, out_shape)\n",
    "# manually perform sum_pool\n",
    "probs = torch.reshape(rf_u, out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "sum_val = torch.zeros_like(rf_u)\n",
    "sum_val = torch.add(sum_val, torch.sum(rf_u, dim=-1, keepdim=True))\n",
    "sum_val = torch.reshape(sum_val, out_shape)\n",
    "samples = torch.reshape(torch.distributions.Multinomial(probs=torch.softmax(rf_u, -1)).sample(), out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(sum_val, samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.rf_pool defaults\n",
    "u = torch.rand(1,10,16,16)\n",
    "torch.random.manual_seed(0)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.rf_pool(u)\n",
    "# manually perform ops.rf_pool with defaults\n",
    "torch.random.manual_seed(0)\n",
    "b = []\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        b.append(u[:,:,r::2,c::2].unsqueeze(-1))\n",
    "b = torch.cat(b, -1)\n",
    "tmp_probs, tmp_samples, tmp_p_probs, tmp_p_samples = ops.prob_max_pool(b, b.shape)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "p_probs = torch.zeros(1,10,8,8)\n",
    "p_samples = torch.zeros(1,10,8,8)\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        probs[:,:,r::2,c::2] = tmp_probs[:,:,:,:,r*2+c]\n",
    "        samples[:,:,r::2,c::2] = tmp_samples[:,:,:,:,r*2+c]\n",
    "        p_probs = torch.max(p_probs, tmp_p_probs[:,:,:,:,r*2+c])\n",
    "        p_samples = torch.max(p_samples, tmp_p_samples[:,:,:,:,r*2+c])\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.rf_pool top-down, div_norm, block_size, pool_args\n",
    "u = torch.rand(1,10,16,16)\n",
    "t = torch.rand(1,10,4,4)\n",
    "torch.random.manual_seed(0)\n",
    "pool_type = 'div_norm'\n",
    "block_size = (4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.rf_pool(u, t, pool_type=pool_type, \n",
    "                                                 block_size=block_size, n=1., sigma=0.5)\n",
    "# manually perform ops.rf_pool with top-down, div_norm, block_size, pool_args\n",
    "b = []\n",
    "for r in range(block_size[0]):\n",
    "    for c in range(block_size[1]):\n",
    "        u[:,:,r::block_size[0],c::block_size[1]].add_(t)\n",
    "        b.append(u[:,:,r::block_size[0],c::block_size[1]].unsqueeze(-1))\n",
    "b = torch.cat(b, -1)\n",
    "# get tmp_probs, tmp_samples from div_norm_pool using pool_args\n",
    "torch.random.manual_seed(0)\n",
    "tmp_probs, tmp_samples, tmp_p_probs, tmp_p_samples = ops.div_norm_pool(b, b.shape, mask=None,\n",
    "                                                                       n=1., sigma=0.5)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "# get probs, samples, p_probs, p_samples\n",
    "p_probs = torch.zeros_like(t)\n",
    "p_samples = torch.zeros_like(t)\n",
    "for r in range(block_size[0]):\n",
    "    for c in range(block_size[1]):\n",
    "        probs[:,:,r::block_size[0],c::block_size[1]] = tmp_probs[:,:,:,:,r*block_size[0]+c]\n",
    "        samples[:,:,r::block_size[0],c::block_size[1]] = tmp_samples[:,:,:,:,r*block_size[0]+c]\n",
    "        p_probs = torch.max(p_probs, tmp_p_probs[:,:,:,:,r*block_size[0]+c])\n",
    "        p_samples = torch.max(p_samples, tmp_p_samples[:,:,:,:,r*block_size[0]+c])\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.rf_pool kernels with batch_size > 1\n",
    "mu, sigma = lattice.init_uniform_lattice((8,8), 4, 4, 1.)\n",
    "delta_mu = torch.rand(2,1,16,2)\n",
    "delta_sigma = torch.rand(2,1,16,1)\n",
    "mu = mu + delta_mu\n",
    "sigma = sigma + delta_sigma\n",
    "rfs = lattice.gaussian_kernel_lattice(mu, sigma, (16,16))\n",
    "u = torch.rand(2,10,16,16)\n",
    "torch.random.manual_seed(0)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.rf_pool(u, rfs=rfs, pool_type='sum', block_size=(1,1))\n",
    "# manually perform pooling with gaussian rfs\n",
    "u.unsqueeze_(2)\n",
    "rf_u = torch.mul(u, rfs)\n",
    "rf_index = torch.as_tensor(torch.gt(rfs, 1e-5), dtype=rf_u.dtype)\n",
    "torch.random.manual_seed(0)\n",
    "probs, samples, p_probs, p_samples = ops.sum_pool(rf_u.flatten(-2), rf_u.shape, rf_index.flatten(-2))\n",
    "probs = torch.max(probs, -3)[0]\n",
    "samples = torch.max(samples, -3)[0]\n",
    "p_probs = torch.max(p_probs, -3)[0]\n",
    "p_samples = torch.max(p_samples, -3)[0]\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0.025917944964021444\n",
      "add: 0.003499198006466031\n"
     ]
    }
   ],
   "source": [
    "# test time taken for indexing or adding mask\n",
    "s = timeit.default_timer()\n",
    "rfs = torch.add(torch.zeros_like(u), rfs)\n",
    "g_u = torch.mul(u, rfs).permute(2,0,1,3,4)\n",
    "rf_index = torch.gt(rfs, 1e-5).permute(2,0,1,3,4)\n",
    "rf_u0 = torch.zeros_like(g_u) - np.inf\n",
    "rf_u0[rf_index] = g_u[rf_index]\n",
    "e = timeit.default_timer()\n",
    "print('index:', e - s)\n",
    "\n",
    "s = timeit.default_timer()\n",
    "rfs = torch.add(torch.zeros_like(u), rfs)\n",
    "g_u = torch.mul(u, rfs).permute(2,0,1,3,4)\n",
    "# create rf_mask of 0s at rf and -inf elsewhere (optimized)\n",
    "thr = 1e-5\n",
    "rf_mask = torch.as_tensor(torch.le(rfs.permute(2,0,1,3,4), thr), dtype=g_u.dtype)\n",
    "rf_mask = -1. * torch.exp(np.inf * (2. * rf_mask - 1.))\n",
    "rf_u1 = torch.add(g_u, rf_mask)\n",
    "e = timeit.default_timer()\n",
    "print('add:', e - s)\n",
    "assert torch.all(torch.eq(rf_u0, rf_u1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05273100297199562\n",
      "0.04342709400225431\n"
     ]
    }
   ],
   "source": [
    "# testing indexing vs. all at once for applying pool_fn across receptive fields\n",
    "# for loop\n",
    "n_kernels = 25\n",
    "mask_thr = 1e-5\n",
    "rf_kernels = torch.rand(2,10,n_kernels,28,28)\n",
    "u_t = torch.rand(2,10,n_kernels,28,28)\n",
    "\n",
    "s = timeit.default_timer()\n",
    "h_mean = torch.zeros(2,10,28,28)\n",
    "h_sample = torch.zeros(2,10,28,28)\n",
    "p_mean = torch.zeros(2,10,28,28)\n",
    "p_sample = torch.zeros(2,10,28,28)\n",
    "\n",
    "rf_u = torch.mul(u_t, rf_kernels).permute(2,0,1,3,4)\n",
    "\n",
    "# create rf_mask of receptive field kernels\n",
    "rf_mask = torch.as_tensor(torch.gt(rf_kernels, mask_thr).permute(2,0,1,3,4),\n",
    "                          dtype=rf_u.dtype)\n",
    "rf_mask = torch.flatten(rf_mask, -2)\n",
    "for u, rf in zip(rf_u, rf_mask):\n",
    "    # apply pool function across image dims\n",
    "    h_mean_i, h_sample_i, p_mean_i, p_sample_i = ops.prob_max_pool(u.flatten(-2), u.shape,\n",
    "                                                             mask=rf)\n",
    "    # max across receptive fields\n",
    "    h_mean = torch.max(h_mean, h_mean_i)\n",
    "    h_sample = torch.max(h_sample, h_sample_i)\n",
    "    p_mean = torch.max(p_mean, p_mean_i)\n",
    "    p_sample = torch.max(p_sample, p_sample_i)\n",
    "    \n",
    "e = timeit.default_timer()\n",
    "print(e - s)\n",
    "\n",
    "# all at once\n",
    "rf_kernels = torch.rand(2,10,n_kernels,28,28)\n",
    "u_t = torch.rand(2,10,n_kernels,28,28)\n",
    "\n",
    "s = timeit.default_timer()\n",
    "rf_u = torch.mul(u_t, rf_kernels)\n",
    "\n",
    "# create rf_mask of receptive field kernels\n",
    "rf_mask = torch.as_tensor(torch.gt(rf_kernels, mask_thr),\n",
    "                          dtype=rf_u.dtype)\n",
    "\n",
    "# apply pool function across image dims\n",
    "h_mean, h_sample, p_mean, p_sample = ops.prob_max_pool(rf_u.flatten(-2), rf_u.shape,\n",
    "                                                         mask=rf_mask.flatten(-2))\n",
    "# max across receptive fields\n",
    "h_mean = torch.max(h_mean, -3)[0]\n",
    "h_sample = torch.max(h_sample, -3)[0]\n",
    "p_mean = torch.max(p_mean, -3)[0]\n",
    "p_sample = torch.max(p_sample, -3)[0]\n",
    "    \n",
    "e = timeit.default_timer()\n",
    "print(e - s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
