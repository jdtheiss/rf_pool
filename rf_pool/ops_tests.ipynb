{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import timeit\n",
    "import torch\n",
    "import numpy as np\n",
    "import ops\n",
    "from utils import lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ops' from '/Users/theissjd/Documents/Berkeley/code/rf_pool/rf_pool/ops.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.average_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.average_pool(rf_u, out_shape)\n",
    "# manually perform average_pool\n",
    "probs = torch.div(rf_u, rf_u.shape[-1])\n",
    "assert torch.all(torch.eq(h_mean, torch.reshape(probs, out_shape)))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=torch.softmax(probs, -1)).sample()\n",
    "assert torch.all(torch.eq(h_sample, torch.reshape(samples, out_shape)))\n",
    "p_probs = torch.mul(probs, samples)\n",
    "assert torch.all(torch.eq(p_mean, torch.reshape(p_probs, out_shape)))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, torch.reshape(p_samples, out_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.div_norm_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "n = 2.\n",
    "sigma = 0.5\n",
    "h_mean, h_sample, p_mean, p_sample = ops.div_norm_pool(rf_u, out_shape, n=n, sigma=sigma)\n",
    "# manually perform div_norm_pool\n",
    "rf_u_n = torch.pow(rf_u, n)\n",
    "sigma_n = torch.pow(torch.as_tensor(sigma, dtype=rf_u.dtype), n)\n",
    "probs = torch.div(rf_u_n, sigma_n + torch.sum(rf_u_n, dim=-1, keepdim=True))\n",
    "assert torch.all(torch.eq(h_mean, torch.reshape(probs, out_shape)))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=torch.softmax(probs, -1)).sample()\n",
    "assert torch.all(torch.eq(h_sample, torch.reshape(samples, out_shape)))\n",
    "p_probs = torch.reshape(torch.mul(probs, samples), out_shape)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = torch.reshape(samples, out_shape)\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.prob_max_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.prob_max_pool(rf_u, out_shape)\n",
    "# manually perform prob_max_pool\n",
    "rf_u_0 = torch.cat([rf_u, torch.zeros(1,10,1)], -1)\n",
    "rf_u_0_softmax = torch.softmax(rf_u_0, -1)\n",
    "probs = torch.reshape(rf_u_0_softmax[:,:,:-1], out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=rf_u_0_softmax).sample()\n",
    "samples = torch.reshape(samples[:,:,:-1], out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(torch.reshape(1. - rf_u_0_softmax[:,:,-1], (1,10,1,1)), samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.stochastic_max_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.stochastic_max_pool(rf_u, out_shape)\n",
    "# manually perform prob_max_pool\n",
    "rf_u_softmax = torch.softmax(rf_u, -1)\n",
    "probs = torch.reshape(rf_u_softmax, out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=rf_u_softmax).sample()\n",
    "samples = torch.reshape(samples, out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(probs, samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.sum_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.sum_pool(rf_u, out_shape)\n",
    "# manually perform sum_pool\n",
    "probs = torch.reshape(rf_u, out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.zeros_like(rf_u)\n",
    "samples.add_(torch.sum(rf_u, dim=-1, keepdim=True))\n",
    "samples = torch.reshape(samples, out_shape)\n",
    "sampled_pos = torch.reshape(torch.distributions.Multinomial(probs=torch.softmax(rf_u, -1)).sample(), out_shape)\n",
    "samples = torch.mul(samples, sampled_pos)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(h_mean, sampled_pos)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = torch.mul(h_sample, sampled_pos)\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.rf_pool defaults #TODO: update with p_mean, p_sample\n",
    "u = torch.rand(1,10,16,16)\n",
    "torch.random.manual_seed(0)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.rf_pool(u)\n",
    "# manually perform ops.rf_pool with defaults\n",
    "torch.random.manual_seed(0)\n",
    "b = []\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        b.append(u[:,:,r::2,c::2].unsqueeze(-1))\n",
    "b = torch.cat(b, -1)\n",
    "tmp_probs, tmp_samples, tmp_p_probs, tmp_p_samples = ops.prob_max_pool(b, b.shape)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "p_probs = torch.zeros(1,10,8,8)\n",
    "p_samples = torch.zeros(1,10,8,8)\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        probs[:,:,r::2,c::2] = tmp_probs[:,:,:,:,r*2+c]\n",
    "        samples[:,:,r::2,c::2] = tmp_samples[:,:,:,:,r*2+c]\n",
    "        p_probs = torch.max(p_probs, tmp_p_probs[:,:,:,:,r*2+c])\n",
    "        p_samples = torch.max(p_samples, tmp_p_samples[:,:,:,:,r*2+c])\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.rf_pool top-down, div_norm, block_size, pool_args #TODO: update with p_mean, p_sample\n",
    "u = torch.rand(1,10,16,16)\n",
    "t = torch.rand(1,10,4,4)\n",
    "torch.random.manual_seed(0)\n",
    "pool_type = 'div_norm'\n",
    "block_size = (4,4)\n",
    "pool_args = [1., 0.5]\n",
    "h_mean, h_sample, p_mean, p_sample = ops.rf_pool(u, t, pool_type=pool_type, \n",
    "                                             block_size=block_size, pool_args=pool_args)\n",
    "# manually perform ops.rf_pool with top-down, div_norm, block_size, pool_args\n",
    "b = []\n",
    "for r in range(block_size[0]):\n",
    "    for c in range(block_size[1]):\n",
    "        u[:,:,r::block_size[0],c::block_size[1]].add_(t)\n",
    "        b.append(u[:,:,r::block_size[0],c::block_size[1]].unsqueeze(-1))\n",
    "b = torch.cat(b, -1)\n",
    "# get tmp_probs, tmp_samples from div_norm_pool using pool_args\n",
    "torch.random.manual_seed(0)\n",
    "tmp_probs, tmp_samples, tmp_p_probs, tmp_p_samples = ops.div_norm_pool(b, b.shape, *pool_args)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "# get probs, samples, p_probs, p_samples\n",
    "p_probs = torch.zeros_like(t)\n",
    "p_samples = torch.zeros_like(t)\n",
    "for r in range(block_size[0]):\n",
    "    for c in range(block_size[1]):\n",
    "        probs[:,:,r::block_size[0],c::block_size[1]] = tmp_probs[:,:,:,:,r*block_size[0]+c]\n",
    "        samples[:,:,r::block_size[0],c::block_size[1]] = tmp_samples[:,:,:,:,r*block_size[0]+c]\n",
    "        p_probs = torch.max(p_probs, tmp_p_probs[:,:,:,:,r*block_size[0]+c])\n",
    "        p_samples = torch.max(p_samples, tmp_p_samples[:,:,:,:,r*block_size[0]+c])\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test ops.rf_pool kernels with batch_size > 1\n",
    "mu, sigma = lattice.init_uniform_lattice((8,8), 4, 4, 1.)\n",
    "delta_mu = torch.rand(2,1,16,2)\n",
    "delta_sigma = torch.rand(2,1,16,1)\n",
    "mu = mu + delta_mu\n",
    "sigma = sigma + delta_sigma\n",
    "rfs = lattice.gaussian_kernel_lattice(mu, sigma, (16,16))\n",
    "u = torch.rand(2,10,16,16)\n",
    "torch.random.manual_seed(0)\n",
    "h_mean, h_sample, p_mean, p_sample = ops.rf_pool(u, rfs=rfs, pool_type='sum', block_size=(1,1))\n",
    "# manually perform pooling with gaussian rfs\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "p_probs = torch.zeros_like(u)\n",
    "p_samples = torch.zeros_like(u)\n",
    "u.unsqueeze_(2)\n",
    "rfs = torch.add(torch.zeros_like(u), rfs)\n",
    "g_u = torch.mul(u, rfs).permute(2,0,1,3,4)\n",
    "rf_index = torch.gt(rfs, 1e-5).permute(2,0,1,3,4)\n",
    "rf_u = torch.zeros_like(g_u) - np.inf\n",
    "rf_u[rf_index] = g_u[rf_index]\n",
    "torch.random.manual_seed(0)\n",
    "probs, samples, p_probs, p_samples = ops.sum_pool(rf_u.flatten(-2), rf_u.shape)\n",
    "probs = torch.max(probs, 0)[0]\n",
    "samples = torch.max(samples, 0)[0]\n",
    "p_probs = torch.max(p_probs, 0)[0]\n",
    "p_samples = torch.max(p_samples, 0)[0]\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0.030836334044579417\n",
      "add: 0.0014781790086999536\n"
     ]
    }
   ],
   "source": [
    "# test time taken for indexing or adding mask\n",
    "s = timeit.default_timer()\n",
    "rfs = torch.add(torch.zeros_like(u), rfs)\n",
    "g_u = torch.mul(u, rfs).permute(2,0,1,3,4)\n",
    "rf_index = torch.gt(rfs, 1e-5).permute(2,0,1,3,4)\n",
    "rf_u0 = torch.zeros_like(g_u) - np.inf\n",
    "rf_u0[rf_index] = g_u[rf_index]\n",
    "e = timeit.default_timer()\n",
    "print('index:', e - s)\n",
    "\n",
    "s = timeit.default_timer()\n",
    "rfs = torch.add(torch.zeros_like(u), rfs)\n",
    "g_u = torch.mul(u, rfs).permute(2,0,1,3,4)\n",
    "# create rf_mask of 0s at rf and -inf elsewhere (optimized)\n",
    "thr = 1e-5\n",
    "rf_mask = torch.as_tensor(torch.le(rfs.permute(2,0,1,3,4), thr), dtype=g_u.dtype)\n",
    "rf_mask = -1. * torch.exp(np.inf * (2. * rf_mask - 1.))\n",
    "rf_u1 = torch.add(g_u, rf_mask)\n",
    "e = timeit.default_timer()\n",
    "print('add:', e - s)\n",
    "assert torch.all(torch.eq(rf_u0, rf_u1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
