{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import rf\n",
    "from utils import lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.average_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = rf.average_pool(rf_u, out_shape)\n",
    "# manually perform average_pool\n",
    "probs = torch.div(rf_u, rf_u.shape[-1])\n",
    "assert torch.all(torch.eq(h_mean, torch.reshape(probs, out_shape)))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=torch.softmax(probs, -1)).sample()\n",
    "assert torch.all(torch.eq(h_sample, torch.reshape(samples, out_shape)))\n",
    "p_probs = torch.mul(probs, samples)\n",
    "assert torch.all(torch.eq(p_mean, torch.reshape(p_probs, out_shape)))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, torch.reshape(p_samples, out_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.div_norm_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "n = 2.\n",
    "sigma = 0.5\n",
    "h_mean, h_sample, p_mean, p_sample = rf.div_norm_pool(rf_u, out_shape, n=n, sigma=sigma)\n",
    "# manually perform div_norm_pool\n",
    "rf_u_n = torch.pow(rf_u, n)\n",
    "sigma_n = torch.pow(torch.as_tensor(sigma, dtype=rf_u.dtype), n)\n",
    "probs = torch.div(rf_u_n, sigma_n + torch.sum(rf_u_n, dim=-1, keepdim=True))\n",
    "assert torch.all(torch.eq(h_mean, torch.reshape(probs, out_shape)))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=torch.softmax(probs, -1)).sample()\n",
    "assert torch.all(torch.eq(h_sample, torch.reshape(samples, out_shape)))\n",
    "p_probs = torch.reshape(torch.mul(probs, samples), out_shape)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = torch.reshape(samples, out_shape)\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.prob_max_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = rf.prob_max_pool(rf_u, out_shape)\n",
    "# manually perform prob_max_pool\n",
    "rf_u_0 = torch.cat([rf_u, torch.zeros(1,10,1)], -1)\n",
    "rf_u_0_softmax = torch.softmax(rf_u_0, -1)\n",
    "probs = torch.reshape(rf_u_0_softmax[:,:,:-1], out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=rf_u_0_softmax).sample()\n",
    "samples = torch.reshape(samples[:,:,:-1], out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(torch.reshape(1. - rf_u_0_softmax[:,:,-1], (1,10,1,1)), samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.stochastic_max_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = rf.stochastic_max_pool(rf_u, out_shape)\n",
    "# manually perform prob_max_pool\n",
    "rf_u_softmax = torch.softmax(rf_u, -1)\n",
    "probs = torch.reshape(rf_u_softmax, out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.distributions.Multinomial(probs=rf_u_softmax).sample()\n",
    "samples = torch.reshape(samples, out_shape)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(probs, samples)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = samples.clone()\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.sum_pool\n",
    "rf_u = torch.rand(1,10,16)\n",
    "torch.random.manual_seed(0)\n",
    "out_shape = (1,10,4,4)\n",
    "h_mean, h_sample, p_mean, p_sample = rf.sum_pool(rf_u, out_shape)\n",
    "# manually perform sum_pool\n",
    "probs = torch.reshape(rf_u, out_shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "torch.random.manual_seed(0)\n",
    "samples = torch.zeros_like(rf_u)\n",
    "samples.add_(torch.sum(rf_u, dim=-1, keepdim=True))\n",
    "samples = torch.reshape(samples, out_shape)\n",
    "sampled_pos = torch.reshape(torch.distributions.Multinomial(probs=torch.softmax(rf_u, -1)).sample(), out_shape)\n",
    "samples = torch.mul(samples, sampled_pos)\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "p_probs = torch.mul(h_mean, sampled_pos)\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "p_samples = torch.mul(h_sample, sampled_pos)\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.pool defaults #TODO: update with p_mean, p_sample\n",
    "u = torch.rand(1,10,16,16)\n",
    "torch.random.manual_seed(0)\n",
    "h_mean, h_sample, p_mean, p_sample = rf.pool(u)\n",
    "# manually perform rf.pool with defaults\n",
    "torch.random.manual_seed(0)\n",
    "b = []\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        b.append(u[:,:,r::2,c::2].unsqueeze(-1))\n",
    "b = torch.cat(b, -1)\n",
    "tmp_probs, tmp_samples, tmp_p_probs, tmp_p_samples = rf.prob_max_pool(b, b.shape)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "p_probs = torch.zeros(1,10,8,8)\n",
    "p_samples = torch.zeros(1,10,8,8)\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        probs[:,:,r::2,c::2] = tmp_probs[:,:,:,:,r*2+c]\n",
    "        samples[:,:,r::2,c::2] = tmp_samples[:,:,:,:,r*2+c]\n",
    "        p_probs = torch.max(p_probs, tmp_p_probs[:,:,:,:,r*2+c])\n",
    "        p_samples = torch.max(p_samples, tmp_p_samples[:,:,:,:,r*2+c])\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.pool top-down, div_norm, block_size, pool_args #TODO: update with p_mean, p_sample\n",
    "u = torch.rand(1,10,16,16)\n",
    "t = torch.rand(1,10,4,4)\n",
    "torch.random.manual_seed(0)\n",
    "pool_type = 'div_norm'\n",
    "block_size = (4,4)\n",
    "pool_args = [1., 0.5]\n",
    "h_mean, h_sample, p_mean, p_sample = rf.pool(u, t, pool_type=pool_type, \n",
    "                                             block_size=block_size, pool_args=pool_args)\n",
    "# manually perform rf.pool with top-down, div_norm, block_size, pool_args\n",
    "b = []\n",
    "for r in range(block_size[0]):\n",
    "    for c in range(block_size[1]):\n",
    "        u[:,:,r::block_size[0],c::block_size[1]].add_(t)\n",
    "        b.append(u[:,:,r::block_size[0],c::block_size[1]].unsqueeze(-1))\n",
    "b = torch.cat(b, -1)\n",
    "# get tmp_probs, tmp_samples from div_norm_pool using pool_args\n",
    "torch.random.manual_seed(0)\n",
    "tmp_probs, tmp_samples, tmp_p_probs, tmp_p_samples = rf.div_norm_pool(b, b.shape, *pool_args)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "# get probs, samples, p_probs, p_samples\n",
    "p_probs = torch.zeros_like(t)\n",
    "p_samples = torch.zeros_like(t)\n",
    "for r in range(block_size[0]):\n",
    "    for c in range(block_size[1]):\n",
    "        probs[:,:,r::block_size[0],c::block_size[1]] = tmp_probs[:,:,:,:,r*block_size[0]+c]\n",
    "        samples[:,:,r::block_size[0],c::block_size[1]] = tmp_samples[:,:,:,:,r*block_size[0]+c]\n",
    "        p_probs = torch.max(p_probs, tmp_p_probs[:,:,:,:,r*block_size[0]+c])\n",
    "        p_samples = torch.max(p_samples, tmp_p_samples[:,:,:,:,r*block_size[0]+c])\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test rf.pool kernels\n",
    "mu, sigma = lattice.init_uniform_lattice((8,8), 4, 4, 1.)\n",
    "rfs = lattice.gaussian_kernel_lattice(mu, sigma, (16,16))\n",
    "u = torch.rand(1,10,16,16)\n",
    "torch.random.manual_seed(0)\n",
    "h_mean, h_sample, p_mean, p_sample = rf.pool(u, rfs=rfs, block_size=(1,1))\n",
    "# manually perform pooling with gaussian rfs\n",
    "torch.random.manual_seed(0)\n",
    "probs = torch.zeros_like(u)\n",
    "samples = torch.zeros_like(u)\n",
    "p_probs = torch.zeros_like(u)\n",
    "p_samples = torch.zeros_like(u)\n",
    "rfs = rfs.reshape(-1, 1, 1, 16, 16)\n",
    "g_u = torch.mul(u.unsqueeze(0), rfs)\n",
    "rf_index = torch.gt(rfs, 1e-5)\n",
    "rf_index = rf_index.repeat(1, 1, 10, 1, 1)\n",
    "for i, rf_i in enumerate(rf_index):\n",
    "    rf_u = g_u[i][rf_i]\n",
    "    [\n",
    "        probs[rf_i], samples[rf_i], \n",
    "        p_probs[rf_i], p_samples[rf_i]\n",
    "    ] = rf.prob_max_pool(rf_u.reshape(1, 10, -1), rf_u.shape)\n",
    "assert torch.all(torch.eq(h_mean, probs))\n",
    "assert torch.all(torch.eq(h_sample, samples))\n",
    "assert torch.all(torch.eq(p_mean, p_probs))\n",
    "assert torch.all(torch.eq(p_sample, p_samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
