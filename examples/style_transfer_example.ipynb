{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "import imp\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load VGG16 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights from vgg16\n",
    "model_dict = OrderedDict()\n",
    "for name, param in vgg16.named_parameters():\n",
    "    if name.startswith('features'):\n",
    "        model_dict.update({name: param})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build part of vgg model\n",
    "model = rf_pool.models.FeedForwardNetwork()\n",
    "model.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(3, 64, 3), activation=torch.nn.ReLU()))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(64, 64, 3), activation=torch.nn.ReLU(),\n",
    "                                            pool=torch.nn.MaxPool2d(2, 2)))\n",
    "model.append('2', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(64, 128, 3), activation=torch.nn.ReLU()))\n",
    "model.append('3', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(128, 128, 3), activation=torch.nn.ReLU(),\n",
    "                                             pool=torch.nn.MaxPool2d(2, 2)))\n",
    "model.append('4', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(128, 256, 3), activation=torch.nn.ReLU()))\n",
    "model.append('5', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(256, 256, 3), activation=torch.nn.ReLU()))\n",
    "model.append('6', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(256, 256, 3), activation=torch.nn.ReLU(),\n",
    "                                             pool=torch.nn.MaxPool2d(2, 2)))\n",
    "model.append('7', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(256, 512, 3), activation=torch.nn.ReLU()))\n",
    "model.append('8', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(512, 512, 3), activation=torch.nn.ReLU()))\n",
    "model.append('9', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(512, 512, 3), activation=torch.nn.ReLU(),\n",
    "                                             pool=torch.nn.MaxPool2d(2, 2)))\n",
    "model.append('10', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(512, 512, 3), activation=torch.nn.ReLU()))\n",
    "model.append('11', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(512, 512, 3), activation=torch.nn.ReLU()))\n",
    "model.append('12', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(512, 512, 3), activation=torch.nn.ReLU(),\n",
    "                                             pool=torch.nn.MaxPool2d(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict for model key to vgg_16 key\n",
    "param_keys = model.download_weights().keys()\n",
    "param_dict = OrderedDict()\n",
    "for (key, val) in zip(param_keys, model_dict.keys()):\n",
    "    param_dict.update({key: val})\n",
    "\n",
    "# load vgg16 weights into model\n",
    "model.load_weights(model_dict, param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that weights were loaded by viewing first layer\n",
    "model.show_weights('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights for later re-use\n",
    "model.save_model('vgg.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading previous\n",
    "model.load_model('vgg.pkl');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Image Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set transform\n",
    "transform = transforms.Compose([transforms.CenterCrop((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                rf_pool.ops.Op(lambda x: x / torch.max(x)),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls for dataset\n",
    "base_url = 'https://random-ize.com/random-art-gallery/'\n",
    "# set url dataset\n",
    "paintset = rf_pool.utils.datasets.URLDataset('.', urls=[base_url], transform=transform,\n",
    "                                             find_img_url=True, url_pattern='src=\"(.+\\.jpg)\"',\n",
    "                                             url_replace=['/random-art-gallery/', base_url])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get urls for dataset\n",
    "base_url = 'https://loremflickr.com/300/300'\n",
    "# set url dataset\n",
    "catset = rf_pool.utils.datasets.URLDataset('.', urls=[base_url], transform=transform,\n",
    "                                           find_url=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Style Transfer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_loss_fn(target, seed):\n",
    "    t = torch.flatten(target, -2) \n",
    "    t = torch.matmul(t, t.transpose(-2,-1))\n",
    "    s = torch.flatten(seed, -2)\n",
    "    s = torch.matmul(s, s.transpose(-2,-1))\n",
    "    return torch.nn.MSELoss()(t, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Content and Style Images\n",
    "content_img = catset[0][0].unsqueeze(0)\n",
    "plt.imshow(rf_pool.utils.functions.normalize_range(content_img[0]).permute(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "style_img = paintset[0][0].unsqueeze(0)\n",
    "plt.imshow(rf_pool.utils.functions.normalize_range(style_img[0]).permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style Transfer with Content and Style Losses\n",
    "seed = torch.rand_like(content_img, requires_grad=True)\n",
    "\n",
    "content_loss = rf_pool.losses.LayerLoss(model, torch.nn.MSELoss(), ['2','4'], input_target=content_img)\n",
    "style_loss = rf_pool.losses.LayerLoss(model, gram_loss_fn, ['2','4','7','10','11'], input_target=style_img)\n",
    "loss_fn = rf_pool.losses.MultiLoss(losses=[content_loss, style_loss], weights=[100., 0.001])\n",
    "\n",
    "optim = torch.optim.SGD([seed], lr=5e-3, momentum=0.9)\n",
    "model.optimize_texture(1000, [], seed, loss_fn, \n",
    "                       optim, monitor=5, show_images=[content_img,style_img,seed], figsize=(10,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
