{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rf_pool import modules, models\n",
    "from rf_pool.utils import functions, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp.reload(datasets)\n",
    "imp.reload(functions)\n",
    "imp.reload(modules)\n",
    "imp.reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='../rf_pool/data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = rf_pool.models.FeedForwardNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rf pooling layer\n",
    "img_shape = torch.as_tensor((24,24))\n",
    "mu, sigma = rf_pool.utils.lattice.init_uniform_lattice(img_shape//2, 4, 7, sigma_init=2.)\n",
    "rf_layer = rf_pool.layers.RF_Pool(mu=mu, sigma=sigma, img_shape=img_shape, \n",
    "                                  lattice_fn=rf_pool.utils.lattice.mask_kernel_lattice,\n",
    "                                  pool_type='max', kernel_size=2)\n",
    "rf_layer.show_lattice()\n",
    "print(mu.shape)\n",
    "n_kernels = mu.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set control network for updating mu/sigma\n",
    "control_net = rf_pool.models.FeedForwardNetwork()\n",
    "control_net.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(16,32,10), activation=torch.nn.ReLU()))\n",
    "control_net.append('1', rf_pool.modules.FeedForward(input_shape=(-1,32*15*15), hidden=torch.nn.Linear(32*15*15,128), \n",
    "                                                 activation=torch.nn.ReLU()))\n",
    "branch0 = rf_pool.modules.FeedForward(hidden=torch.nn.Linear(128,n_kernels*2), activation=torch.nn.Tanh())\n",
    "branch1 = rf_pool.modules.FeedForward(hidden=torch.nn.Linear(128,n_kernels), activation=torch.nn.Tanh())\n",
    "control_net.append('2', rf_pool.modules.Branch([branch0, branch1],\n",
    "                                            branch_shapes=[(-1,1,n_kernels,2), (-1,1,n_kernels,1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# append layers of model\n",
    "model.append('0', rf_pool.modules.Control(hidden=torch.nn.Conv2d(1,16,5), activation=torch.nn.ReLU(), \n",
    "                                       control=control_net, pool=rf_layer))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(16,32,5), activation=torch.nn.ReLU(),\n",
    "                                           pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('2', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(32,64,4)))\n",
    "model.append('3', rf_pool.modules.FeedForward(input_shape=(-1, 64), hidden=torch.nn.Linear(64, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set additional L1 loss on control outputs \n",
    "# note that since control_net outputs two branches the two outputs are flattened and concatenated\n",
    "n_branch_out = np.sum([np.prod(shp) for shp in control_net.output_shapes((1,16,24,24))[-1]])\n",
    "add_loss = {'loss_fn': torch.nn.L1Loss(reduction='sum'), 'target': torch.zeros(n_branch_out),\n",
    "            'layer_ids': ['0'], 'module_name': 'control'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train model, monitor weights and lattice\n",
    "loss_history = model.train(1, trainloader, loss_fn, optim, monitor=100,\n",
    "                           show_weights={'layer_id': '0', 'cmap': 'gray'},\n",
    "                           show_lattice={},\n",
    "                           add_loss=add_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
