{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "import imp\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_pool import models, modules, layers, ops\n",
    "from rf_pool.utils import lattice, functions, visualize, datasets, stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load MNIST Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=True, \n",
    "                                       transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False, download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base set crowded i\n",
    "base_set = pickle.load(open('crowding_experiment/MNIST_CrowdedDataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = rf_pool.models.FeedForwardNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append layers of model\n",
    "model.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(1,32,5),\n",
    "                                              activation=torch.nn.ReLU(), \n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(32,64,5),\n",
    "                                              activation=torch.nn.ReLU(),\n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('2', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(64,10,4)))\n",
    "model.append('3', rf_pool.modules.FeedForward(input_shape=(-1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous model and results\n",
    "(_, extras) = model.load_model('crowding_experiment/attention_3deg.pkl')\n",
    "interference_crop = extras.get('interference_crop')\n",
    "similarity_rfs = extras.get('similarity_rfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reshape layer \n",
    "model.layers.pop('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update RF layer with attention at target location\n",
    "img_shape = torch.Size((53,53))\n",
    "mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.23, 0., n_rf=None, n_rings=11, \n",
    "                                                        offset=[0.,-30.], rotate_rings=False)\n",
    "rf_layer = rf_pool.layers.RF_Pool(mu=mu, sigma=sigma, img_shape=img_shape, \n",
    "                                  lattice_fn=rf_pool.utils.lattice.mask_kernel_lattice,\n",
    "                                  pool_type=None, kernel_size=2, thr=np.exp(-1.))\n",
    "rf_layer.show_lattice()\n",
    "print(rf_layer.mu.shape)\n",
    "n_kernels = rf_layer.mu.shape[0]\n",
    "\n",
    "layer_id = '1'\n",
    "model.layers[layer_id].forward_layer.add_module('pool', rf_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set functions for experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crowd_params(crowd_type):\n",
    "    if crowd_type in ['outer','inner']:\n",
    "        n_flankers = 1\n",
    "    else:\n",
    "        n_flankers = 2\n",
    "    if crowd_type == 'inner':\n",
    "        axis = np.pi\n",
    "    else:\n",
    "        axis = 0.\n",
    "    return n_flankers, axis\n",
    "\n",
    "def create_crowd_set(dataset, n_images, img_size, n_flankers, axis, spacing, base_set=None,\n",
    "                     label_map=None, no_target=False):\n",
    "    if base_set is None:\n",
    "        crowd_set = datasets.CrowdedDataset(dataset, n_flankers, n_images, no_target=no_target,\n",
    "                                            load_previous=False, label_map=label_map,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            spacing=20*spacing, background_size=img_size, axis=axis)\n",
    "    else:\n",
    "        crowd_set = datasets.CrowdedDataset(dataset, n_flankers, n_images,\n",
    "                                            base_set.recorded_target_indices,\n",
    "                                            base_set.recorded_flanker_indices,\n",
    "                                            no_target=no_target,\n",
    "                                            load_previous=True, label_map=label_map,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            spacing=20*spacing, background_size=img_size, axis=axis)\n",
    "    return crowd_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_attention_field(model, layer_id, mu, sigma, loc, extent):\n",
    "    # update rfs with spatial extent\n",
    "    img_shape = model.layers[layer_id].forward_layer.pool.get(['img_shape'])[0]\n",
    "    attn_field = torch.zeros(img_shape)\n",
    "    attn_field[loc[0],loc[1]] = 1./extent\n",
    "    new_mu, new_sigma = lattice.update_mu_sigma(mu, sigma, attn_field)\n",
    "    model.layers[layer_id].forward_layer.pool.set(mu=new_mu, sigma=new_sigma)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_interference(model, layer_id, target, target_flanker, crop):\n",
    "    layer_ids = model.pre_layer_ids(layer_id) + [layer_id]\n",
    "    with torch.no_grad():\n",
    "        target_crop = model.apply_layers(target, layer_ids)[:,:,crop[0],crop[1]].flatten(1)\n",
    "        crowd_crop = model.apply_layers(target_flanker, layer_ids)[:,:,crop[0],crop[1]].flatten(1)\n",
    "    return 1. - functions.pairwise_cosine_similarity(target_crop, crowd_crop)\n",
    "\n",
    "def rf_cosine_similarity(model, layer_id, target, flanker, target_flanker):\n",
    "    with torch.no_grad():\n",
    "        target_rfs = model.rf_output(target, '1', retain_shape=True)[0]\n",
    "        target_rfs = torch.transpose(target_rfs, 1, 2).flatten(2)\n",
    "        target_rfs = torch.mul(target_rfs, model.rf_index(target, '1', thr=0.1).unsqueeze(-1).float())\n",
    "        flanker_rfs = model.rf_output(flanker, '1', retain_shape=True)[0]\n",
    "        flanker_rfs = torch.transpose(flanker_rfs, 1, 2).flatten(2)\n",
    "        flanker_rfs = torch.mul(flanker_rfs, model.rf_index(flanker, '1', thr=0.1).unsqueeze(-1).float())\n",
    "        crowd_rfs = model.rf_output(target_flanker, '1', retain_shape=True)[0]\n",
    "        crowd_rfs = torch.transpose(crowd_rfs, 1, 2).flatten(2)\n",
    "        crowd_rfs = torch.mul(crowd_rfs, model.rf_index(target_flanker, '1', thr=0.1).unsqueeze(-1).float())\n",
    "    target_rfs_sim = functions.pairwise_cosine_similarity(target_rfs, crowd_rfs, axis=-1)\n",
    "    flanker_rfs_sim = functions.pairwise_cosine_similarity(flanker_rfs, crowd_rfs, axis=-1)\n",
    "    return target_rfs_sim, flanker_rfs_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_similarity(x, y):\n",
    "    mask = (torch.isnan(x) * torch.isnan(y)) + (torch.ge(x, 0.9999) * torch.ge(y, 0.9999))\n",
    "    return 1. - mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_gray = cm.get_cmap(\"gray\")\n",
    "font = {'family' : 'arial',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "def plot_interference(x, y, std, label, color, filename=None):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
    "    for var, s, name, c in zip(y, std, label, color):\n",
    "        ax.errorbar(x, var, yerr = s, color=c, lw=3, fmt='o-', label=name, ms=10)\n",
    "    ax.yaxis.grid(which=\"major\", color=cmap_gray(.8), linestyle='--', linewidth=1)\n",
    "    ax.set_xlabel(\"Attentional Field Extent (DVA)\")\n",
    "    ax.set_ylabel(\"Mean Interference\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if filename:\n",
    "        fig.savefig(filename, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get cropped interference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size, image size, and test size\n",
    "batch_size = 1\n",
    "img_size = 118\n",
    "n_test = 1000\n",
    "# set spacing\n",
    "spacing = 1.\n",
    "# set label mapping\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])\n",
    "# get crowded MNIST training data for targets\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map)\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                           shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init crowd interference dictionary\n",
    "interference_crop = {'extent': np.arange(10, 22.5, 2.5),\n",
    "             'outer': [], \n",
    "             'inner': [], \n",
    "             'radial': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each type, get interference\n",
    "for key in ['outer','inner','radial']:\n",
    "    # get crowded MNIST training data\n",
    "    n_flankers, axis = get_crowd_params(key)\n",
    "    crowd_set = create_crowd_set(testset, n_test, img_size, n_flankers, axis, spacing, base_set, label_map)\n",
    "    for e, extent in enumerate(list(interference_crop.get('extent'))):\n",
    "        # apply attention\n",
    "        mu, sigma = lattice.init_foveated_lattice(img_shape, 0.23, 0., n_rf=None, n_rings=11, \n",
    "                                                  offset=[0.,-30.], rotate_rings=False)\n",
    "        model = apply_attention_field(model, '1', mu, sigma, [26,26], extent)\n",
    "        # get interference for each \n",
    "        target_crop_int = []\n",
    "        for i, ((target, _), (target_flanker, _)) in enumerate(zip(target_set, crowd_set)):\n",
    "            # get cropped interference\n",
    "            t_int = cropped_interference(model, layer_id, target.unsqueeze(0),\n",
    "                                         target_flanker.unsqueeze(0),\n",
    "                                         crop=(slice(11,15), slice(11,15)))\n",
    "            if not torch.isnan(t_int):\n",
    "                target_crop_int.append(t_int.item())\n",
    "            # monitor\n",
    "            clear_output(wait=True)\n",
    "            display('%s %s' % (key, extent))\n",
    "            display('%0.3f' % (i / len(target_loader)))\n",
    "            display('interference: %f' % torch.mean(torch.tensor(target_crop_int)))\n",
    "        # update and save\n",
    "        interference_crop.update({key: list(interference_crop.get(key)) + [target_crop_int]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get RF Cosine similarity for (Target, Target+Flanker) and (Flanker, Target+Flanker)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size, image size, and test size\n",
    "batch_size = 1\n",
    "img_size = 118\n",
    "n_test = 100\n",
    "# set spacing\n",
    "spacing = 1.\n",
    "# set label mapping\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])\n",
    "# get crowded MNIST training data for targets\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map)\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                           shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init crowd interference dictionary\n",
    "similarity_rfs = {'extent': np.arange(10, 22.5, 2.5),\n",
    "                 'outer': [], 'outer_flanker': [], \n",
    "                 'inner': [], 'inner_flanker': [], \n",
    "                 'radial': [], 'radial_flanker': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each type, get interference\n",
    "for key in ['outer','inner','radial']:\n",
    "    n_flankers, axis = get_crowd_params(key)\n",
    "    # get flanker/crowded MNIST test data\n",
    "    flanker_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, \n",
    "                                   base_set, label_map, no_target=True)\n",
    "    crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing,\n",
    "                                 base_set, label_map)\n",
    "    for e, extent in enumerate(list(similarity_rfs.get('extent'))):\n",
    "        # update rfs with spatial extent\n",
    "        mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.23, 0., n_rf=None, n_rings=11, \n",
    "                                                                offset=[0.,-30.], rotate_rings=False)\n",
    "        model = apply_attention_field(model, layer_id, mu, sigma, [26,26], extent)\n",
    "        # get interference for each \n",
    "        target_rfs_sim = []\n",
    "        flanker_rfs_sim = []\n",
    "        for i, ((target, _), (flanker, _), (target_flanker, _)) in enumerate(zip(target_set, flanker_set, crowd_set)):\n",
    "            # get cosine similarity \n",
    "            t_sim, f_sim = rf_cosine_similarity(model, layer_id, target.unsqueeze(0), \n",
    "                                                flanker.unsqueeze(0), target_flanker.unsqueeze(0))\n",
    "            target_rfs_sim.append(t_sim)\n",
    "            flanker_rfs_sim.append(f_sim)\n",
    "            # monitor\n",
    "            clear_output(wait=True)\n",
    "            display('%s %s' % (key, extent))\n",
    "            display('%0.3f' % (i / len(target_loader)))\n",
    "        # update similarity rfs dict \n",
    "        similarity_rfs.update({key: list(similarity_rfs.get(key)) + [torch.cat(target_rfs_sim)],\n",
    "                               key + '_flanker': list(similarity_rfs.get(key + '_flanker'))\n",
    "                               + [torch.cat(flanker_rfs_sim)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model and results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('crowding_experiment/attention_3deg.pkl', {'interference_crop': interference_crop, \n",
    "                                                            'similarity_rfs': similarity_rfs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot cropped interference and RF heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interference with extent\n",
    "x = interference_crop.get('extent') / 10.\n",
    "y = [[np.mean(interference_crop.get(key)[i]) for i in range(5)] for key in ['outer','inner','radial']]\n",
    "std = [[np.std(interference_crop.get(key)[i]) for i in range(5)] for key in ['outer','inner','radial']]\n",
    "filename = 'crowding_experiment/attention_experiments.png'\n",
    "plot_interference(x, y, std, ['outer','inner','both'], ['blue','green','orange'], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmaps of attentional differences\n",
    "for key in ['outer','inner','radial']:\n",
    "    for i in [0,-1]:\n",
    "        # update rfs with spatial extent (at center of RF layer)\n",
    "        mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.23, 0., n_rf=None, n_rings=11, \n",
    "                                                                offset=[0.,-30.], rotate_rings=False)\n",
    "        model = apply_attention_field(model, layer_id, mu, sigma, [26,26], similarity_rfs.get('extent')[i])\n",
    "        # get target, flanker similarities\n",
    "        res = str(similarity_rfs.get('extent')[i])\n",
    "        x = similarity_rfs.get(key)[i].clone()\n",
    "        y = similarity_rfs.get(key + '_flanker')[i].clone()\n",
    "        # get mask\n",
    "        mask = mask_similarity(x, y)\n",
    "        mask[:, torch.sum(mask, 0) < 5] = 0\n",
    "        # remove nans from similarities\n",
    "        x[torch.isnan(x)] = 0.\n",
    "        y[torch.isnan(y)] = 0.\n",
    "        # get mean difference between target and flanker similarities\n",
    "        scores = torch.div(torch.sum(torch.mul(x - y, mask), 0), torch.sum(mask, 0))\n",
    "        # get example crowded images\n",
    "        n_flankers, axis = get_crowd_params(key)\n",
    "        crowd_set = create_crowd_set(testset, 1, img_size, n_flankers, axis, spacing, base_set=base_set, \n",
    "                                     label_map=label_map)\n",
    "        visualize.heatmap(model, layer_id, scores, -1., 1., outline_rfs=True, input=crowd_set[0][0][0],\n",
    "                          filename='crowding_experiment/' + key + '_' + res + '_attention_heatmap.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
