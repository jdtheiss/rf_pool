{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "import imp\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_pool import models, modules, pool, ops\n",
    "from rf_pool.utils import lattice, functions, visualize, datasets, stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the figures folder\n",
    "if not os.path.exists('figures'):\n",
    "        os.mkdir('figures')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load MNIST Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='../../data', train=True, download=True, \n",
    "                                       transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='../../data', train=False, download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in crowded digits base set\n",
    "base_set_filename = 'MNIST_CrowdedDataset.pkl'\n",
    "if os.path.exists('datasets/' + base_set_filename):\n",
    "    base_set = pickle.load(open('datasets/' + base_set_filename, 'rb'))\n",
    "else:\n",
    "    base_set = None\n",
    "    \n",
    "# set what labels mmap to what digit\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = rf_pool.models.FeedForwardNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append layers of model\n",
    "model.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(1,32,5),\n",
    "                                              activation=torch.nn.ReLU(), \n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(32,64,5),\n",
    "                                              activation=torch.nn.ReLU(),\n",
    "                                              pool=torch.nn.MaxPool2d(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous model and results\n",
    "(_, extras) = model.load_model('models/MNIST_rate_0.2_10k_3deg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reshape layer \n",
    "model.layers.pop('3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace max pool layer with rf pool layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the rf layer\n",
    "img_shape = torch.Size((53,53))\n",
    "offset = [0., -30.]\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, RF_rate, gap, n_rings=n_rings, std=std,\n",
    "                                                        offset=offset)\n",
    "rf_layer = rf_pool.pool.RF_Pool(mu=mu, sigma=sigma, img_shape=img_shape, \n",
    "                                lattice_fn=rf_pool.utils.lattice.mask_kernel_lattice,\n",
    "                                pool_fn='max_pool', kernel_size=2, retain_shape=True)\n",
    "\n",
    "# append the rf pool layer to the model\n",
    "layer_id = '1'\n",
    "model.layers[layer_id].forward_layer.add_module('pool', rf_layer)\n",
    "visualize.heatmap(model, '1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Figure Paramaters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size, image size, and test size\n",
    "batch_size = 1\n",
    "img_size = 118\n",
    "n_test = 1\n",
    "# set spacing\n",
    "spacing = 1.\n",
    "# set label mapping\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])\n",
    "# get crowded MNIST training data for targets\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map)\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dpi and font types\n",
    "matplotlib.rcParams['figure.dpi'] = 300.\n",
    "font = {'size': 8., 'style': 'normal', 'family': 'times', 'weight': 'normal'}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('pdf', fonttype=42)\n",
    "matplotlib.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Bootstrapped Confidence Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Spacing'\n",
    "index = 3 # 2 for SNR, 3 for accuracy\n",
    "start = ''\n",
    "end = '_space'\n",
    "file = 'results/PSNR_%s_10k.pkl' % task.lower()\n",
    "extras = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extras['confidence_intervals'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in extras.keys():\n",
    "    if not k.startswith(start) or not k.endswith(end):\n",
    "        continue\n",
    "    ci = []\n",
    "    extras['confidence_intervals'].update({k: ci})\n",
    "    for i in range(len(extras[k])):\n",
    "        clear_output(wait=True)\n",
    "        display('%s: %d' % (k, i))\n",
    "        stats = functions.bootstrap(extras[k][i][index], n_samples=1000)\n",
    "        x_m = np.mean(extras[k][i][index])\n",
    "        # better approx. of CI\n",
    "        ci.append(2. * x_m - np.percentile(stats, [97.5, 2.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(extras, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get bootstrapped p-values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "space_exp = pickle.load(open('results/PSNR_spacing_10k.pkl', 'rb'))\n",
    "attn_exp = pickle.load(open('results/PSNR_attention_10k.pkl', 'rb'))\n",
    "density_exp = pickle.load(open('results/PSNR_density_10k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_means(x, y):\n",
    "    return np.mean(x) - np.mean(y)\n",
    "\n",
    "def bootstrap_slope(*args, spacing=None):\n",
    "    assert spacing is not None\n",
    "    assert len(args) % len(spacing) == 0\n",
    "    # get mean for each arg\n",
    "    n_spacing = len(spacing)\n",
    "    y0 = [np.mean(a) for a in args[:n_spacing]]\n",
    "    y1 = [np.mean(a) for a in args[n_spacing:]]\n",
    "    # get slope\n",
    "    A = np.stack([spacing,np.ones(n_spacing)]).T\n",
    "    s_0 = np.abs(np.linalg.lstsq(A, y0, rcond=None)[0][0])\n",
    "    s_1 = np.abs(np.linalg.lstsq(A, y1, rcond=None)[0][0])\n",
    "    return s_0 - s_1\n",
    "\n",
    "def bootstrap_test(*args, fn, n_samples, fn_kwargs={}):\n",
    "    # get initial mean difference\n",
    "    diff0 = fn(*args, **fn_kwargs)\n",
    "    \n",
    "    # get null distribution\n",
    "    n_args = len(args)\n",
    "    x_primes = []\n",
    "    y_primes = []\n",
    "    for x, y in zip(args[:n_args // 2], args[n_args // 2:]):\n",
    "        z = np.concatenate([x,y])\n",
    "        z_mean = np.mean(z)\n",
    "        x_primes.append(x - np.mean(x) + z_mean)\n",
    "        y_primes.append(y - np.mean(y) + z_mean)\n",
    "    args_prime = x_primes + y_primes\n",
    "    # bootstrap resample\n",
    "    diff = np.stack(functions.bootstrap(*args_prime, fn=fn, n_samples=n_samples, \n",
    "                                        fn_kwargs=fn_kwargs))\n",
    "    return np.mean(np.abs(diff) > np.abs(diff0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test radial min extent attention vs. radial 2-spacing\n",
    "keys = ['radial_space', 'radial_attn']\n",
    "p = bootstrap_test(space_exp[keys[0]][-1][3], attn_exp[keys[1]][0][3], fn=bootstrap_means, n_samples=n_samples)\n",
    "print('%s (%a spacing) < %s (%a extent) p-value: %a' % \n",
    "      (keys[0], space_exp['spacing'][-1], keys[1], attn_exp['extent'][0], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test spacing outer vs. inner, radial vs. tangential (pooled across spacings 1 to 1.5)\n",
    "for key in zip(['outer_space', 'radial_space'], ['inner_space','tangential_space']):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, spacing in enumerate(space_exp['spacing']):\n",
    "        # pool across spacings\n",
    "        if spacing in [1., 1.25, 1.5]:\n",
    "            x.extend(space_exp[key[0]][i][3])\n",
    "            y.extend(space_exp[key[1]][i][3])\n",
    "    # bootstrap test between means\n",
    "    p = bootstrap_test(x, y, fn=bootstrap_means, n_samples=n_samples)\n",
    "    print('%s < %s (%a) p-value: %a' % (key[0], key[1], spacing, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test attention outer vs. inner, radial vs. tangential\n",
    "for key in zip(['outer_attn', 'radial_attn'], ['inner_attn','tangential_attn']):\n",
    "    for i, extent in enumerate(attn_exp['extent']):\n",
    "        p = bootstrap_test(attn_exp[key[0]][i][3], attn_exp[key[1]][i][3], \n",
    "                           fn=bootstrap_means, n_samples=n_samples)\n",
    "        print('%s < %s (%a) p-value: %a' % (key[0], key[1], extent, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test slope of density SNR\n",
    "for key in zip(['cost_0','cost_0','cost_1'], ['cost_1','cost_2','cost_2']):\n",
    "    p = bootstrap_test(*[x[2] for x in density_exp[key[0]]], *[x[2] for x in density_exp[key[1]]],\n",
    "                       fn=bootstrap_slope, n_samples=n_samples, fn_kwargs={'spacing': density_exp['spacing']})\n",
    "    print('Sigma %0.2f < %0.2f slope p-value: %a' % \n",
    "          (density_exp['sigma_' + key[0][-1]][0], density_exp['sigma_' + key[1][-1]][0], p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap Figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_file = 'results/PSNR_heatmaps_10k.pkl'\n",
    "figsize = (3.3,3.3)\n",
    "fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "titles = ['Inner', 'Outer', 'Radial', 'Tangential']\n",
    "end = '_hm'\n",
    "layer_id = '1'\n",
    "task = 'Spacing'\n",
    "\n",
    "# load heatmaps    \n",
    "extras = pickle.load(open(heatmap_file, 'rb'))\n",
    "\n",
    "# set indices, extent\n",
    "if task.lower() == 'spacing':\n",
    "    indices = [1,0]\n",
    "    extent = None\n",
    "    spacing = extras['spacing'][-1]\n",
    "else:\n",
    "    indices = [2,0]\n",
    "    extent = extras['extent'][0]\n",
    "    spacing = 1.\n",
    "    \n",
    "# get vmax, diff scores\n",
    "vmax = 0.\n",
    "diff_scores = []\n",
    "for key in titles:\n",
    "    scores = [extras[key.lower() + end][i] for i in indices]\n",
    "    diff = scores[0] - scores[1]\n",
    "    tmp = torch.max(diff[torch.isnan(diff).bitwise_not()])\n",
    "    diff_scores.append(diff)\n",
    "    if tmp > vmax:\n",
    "        vmax = tmp\n",
    "        \n",
    "# get heatmaps into subplots\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        # get flankers, axis, offset\n",
    "        n_flankers, axis = get_crowd_params(titles[r*2 + c].lower())\n",
    "        # create crowd set\n",
    "        crowd_set = create_crowd_set(testset, 1, 118, n_flankers, axis, spacing,\n",
    "                                     base_set=base_set, label_map=label_map)\n",
    "        # update RF offset\n",
    "        mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.2, 0., n_rings=10, std=1.,\n",
    "                                                                offset=offset)\n",
    "        model.layers[layer_id].forward_layer.pool.set(mu=mu, sigma=sigma)\n",
    "        if task.lower() == 'attention':\n",
    "            model = apply_attention_field(model, layer_id, mu, sigma, [26,26], extent)\n",
    "        # get heatmap\n",
    "        fig = visualize.heatmap(model, layer_id, scores=diff_scores[r*2 + c].squeeze(0), cmap='Greens',\n",
    "                                input=crowd_set[0][0][0], RF_alpha=0.1,\n",
    "                                vmin=0., vmax=vmax, ax=axes[r,c], show=False)\n",
    "        axes[r,c].set_title(titles[r*2 + c])\n",
    "\n",
    "# colorbar\n",
    "cbar = plt.colorbar(axes[0,0].get_images()[0], ax=axes)\n",
    "if task.lower() == 'spacing':\n",
    "    cbar_label = 'Max. - Min. %s PSNR (dB)' % task\n",
    "else:\n",
    "    cbar_label = '%s - No %s PSNR (dB)' % (task, task)\n",
    "cbar.ax.set_ylabel(cbar_label, labelpad=10, rotation=270)\n",
    "\n",
    "# update RFs due to colorbar\n",
    "for r in range(2):\n",
    "    for c in range(2):\n",
    "        # update scatter RFs\n",
    "        visualize.scatter_rfs(model, layer_id, updates={'sizes': None}, figsize=figsize, ax=axes[r,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/%s_heatmaps.pdf' % task.lower(), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'radial'\n",
    "end = '_hm'\n",
    "layer_id = '1'\n",
    "task = 'Spacing'\n",
    "spacings = [2., 1., 2.]\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(10., 2.5))\n",
    "indices = [1,0]\n",
    "scores = [extras[key.lower() + end][i] for i in indices]\n",
    "scores.append(scores[0] - scores[1])\n",
    "\n",
    "# get flankers, axis, offset\n",
    "n_flankers, axis = get_crowd_params(key.lower())\n",
    "# create crowd set\n",
    "crowd_set = create_crowd_set(testset, 1, 118, n_flankers, axis, spacing,\n",
    "                             base_set=base_set, label_map=label_map)\n",
    "\n",
    "vmax = torch.max(scores[0][torch.isnan(scores[0]).bitwise_not()]) + 5.\n",
    "vmin = 0.\n",
    "for r in range(3):\n",
    "    # create crowd set\n",
    "    crowd_set = create_crowd_set(testset, 1, 118, n_flankers, axis, spacings[r],\n",
    "                                 base_set=base_set, label_map=label_map)\n",
    "        \n",
    "    visualize.heatmap(model, layer_id, scores=scores[r].squeeze(0), cmap='Greens',\n",
    "                    input=crowd_set[0][0][0], RF_alpha=0.1, vmin=vmin, vmax=vmax,\n",
    "                    ax=axes[r], show=False)\n",
    "    \n",
    "cbar = plt.colorbar(axes[0].get_images()[0], ax=axes)\n",
    "cbar_label = 'Max. - Min. %s PSNR (dB)' % task\n",
    "cbar.ax.set_ylabel(cbar_label, labelpad=10, rotation=270)\n",
    "\n",
    "# update RFs due to colorbar\n",
    "for r in range(3):\n",
    "    # update scatter RFs\n",
    "    visualize.scatter_rfs(model, layer_id, updates={'sizes': None}, figsize=figsize, ax=axes[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/spacing_heatmap_subtraction.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spacing, Attention Heatmap/Accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (7.2, 1.8)\n",
    "fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "spacing = 1.\n",
    "key = 'radial'\n",
    "exps = ['Attention', 'Spacing']\n",
    "ends = ['_attn', '_space']\n",
    "\n",
    "# get data\n",
    "extras = pickle.load(open('results/PSNR_attention_10k.pkl', 'rb'))\n",
    "extras2 = pickle.load(open('results/PSNR_spacing_10k.pkl', 'rb'))\n",
    "heatmap = pickle.load(open('results/PSNR_heatmaps_10k.pkl', 'rb'))\n",
    "extent = heatmap['extent'][0]\n",
    "\n",
    "# get heatmap scores\n",
    "diff_scores = []\n",
    "diff_scores.append(heatmap['radial_hm'][2] - heatmap['radial_hm'][0])\n",
    "diff_scores.append(heatmap['radial_hm'][1] - heatmap['radial_hm'][0])\n",
    "vmax = torch.max(diff_scores[1][torch.isnan(diff_scores[1]).bitwise_not()])\n",
    "\n",
    "# get accuracy and confidence intervals\n",
    "acc_0 = extras[key+ends[0]][0][1]\n",
    "acc_1 = extras2[key+ends[1]][-1][1]\n",
    "ci_0 = np.abs(np.array(extras['confidence_intervals'][key+ends[0]][0]) - acc_0)\n",
    "ci_1 = np.abs(np.array(extras2['confidence_intervals'][key+ends[1]][-1]) - acc_1)\n",
    "\n",
    "# plot accuracy\n",
    "axes[0].bar(exps, [acc_0, acc_1], \n",
    "            color='green', alpha=0.8)\n",
    "axes[0].errorbar([0,1], [acc_0, acc_1], yerr=[ci_0, ci_1], capsize=2., \n",
    "                 color='green', alpha=0.8, fmt='none')\n",
    "axes[0].set_ylabel('Accuracy (Proportion Correct)')\n",
    "# asterisk based on testing radial min extent attention vs. radial 2-spacing\n",
    "axes[0].plot(0.5, 0.6, marker='*', color='Black', markersize=4., markeredgewidth=0.25)\n",
    "\n",
    "# set heatmaps\n",
    "for i, end in enumerate(ends):\n",
    "    # get flankers, axis, offset\n",
    "    n_flankers, axis = get_crowd_params(key)\n",
    "    # create crowd set\n",
    "    spacing = i + 1.\n",
    "    crowd_set = create_crowd_set(testset, 1, 118, n_flankers, axis, spacing,\n",
    "                                 base_set=base_set, label_map=label_map)\n",
    "    # update RF offset\n",
    "    mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.2, 0., n_rings=10, std=1.,\n",
    "                                                            offset=offset)\n",
    "    model.layers[layer_id].forward_layer.pool.set(mu=mu, sigma=sigma)\n",
    "    if i == 0:\n",
    "        model = apply_attention_field(model, layer_id, mu, sigma, [26,26], extent)\n",
    "    # get heatmap\n",
    "    axes[i+1].set_xlabel(exps[i])\n",
    "    visualize.heatmap(model, layer_id, scores=diff_scores[i].squeeze(0), cmap='Greens',\n",
    "                      outline_rfs=True, input=crowd_set[0][0][0], RF_alpha=0.1,\n",
    "                      vmin=0., vmax=vmax, ax=axes[i+1], show=False)\n",
    "    \n",
    "# colorbar\n",
    "cbar = plt.colorbar(axes[2].get_images()[0], ax=fig.axes)\n",
    "cbar_label = 'PSNR Change (dB)'\n",
    "cbar.ax.set_ylabel(cbar_label, labelpad=10, rotation=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/attention_spacing_heatmaps.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy Figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Spacing'\n",
    "extras = pickle.load(open('results/PSNR_%s_10k.pkl' % task.lower(), 'rb'))\n",
    "fig, ax = plt.subplots(1,2, figsize=(4.8, 2.4))\n",
    "colors = ['blue', 'orange','green','red']\n",
    "linestyles = ['--', '-', '-.', ':']\n",
    "end = '_space'\n",
    "\n",
    "# plot spacing accuracy\n",
    "for i, key in enumerate(['outer','inner','radial','tangential']):\n",
    "    acc = np.array([x[1] for x in extras[key+end]]).reshape(-1, 1)\n",
    "    ci = np.abs(np.array(extras['confidence_intervals'][key+end]) - acc).T\n",
    "    ax[1].errorbar(extras['spacing'], acc, yerr=ci, capsize=2., alpha=0.8, color=colors[i],\n",
    "                   linestyle=linestyles[i])\n",
    "ax[1].set_ylabel('Accuracy (Proportion Correct)')\n",
    "ax[1].set_xlabel('Target-Flanker Spacing (DVA)')\n",
    "# ax[1].yaxis.grid(which='major', color='gray', alpha=0.8, linestyle='dashed', linewidth=1.)\n",
    "ax[1].legend(['Outer','Inner','Radial','Tangential'])\n",
    "ax[1].hlines(extras['none'+end][0][1], extras['spacing'][0], extras['spacing'][-1])\n",
    "fig.tight_layout()\n",
    "\n",
    "# create crowded stimulus with 4 flankers\n",
    "crowd_set = create_crowd_set(testset, 1, 118, 4, 0., 1.5, \n",
    "                             base_set=None, label_map=label_map)\n",
    "\n",
    "# create bounding boxes for the different configurations\n",
    "centers = [(59+15,59), (59-15,59), (59, 59), (59, 59)]\n",
    "widths = [56, 56, 90, 30]\n",
    "heights = [26, 22, 30, 90]\n",
    "visualize.bounding_box(ax[0], 4, centers, widths, heights, alpha=0.8, lw=2,\n",
    "                       color=colors, linestyle=linestyles)\n",
    "# add the RF array\n",
    "mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.2, 0., n_rings=10, std=1.,\n",
    "                                                        offset=offset)\n",
    "model.layers[layer_id].forward_layer.pool.set(mu=mu, sigma=sigma)\n",
    "visualize.heatmap(model, '1', input=crowd_set[0][0][0], ax=ax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/%s_acc.pdf' % task.lower(), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Attention'\n",
    "fig, ax = plt.subplots(2,3, figsize=(7.2, 2.8), gridspec_kw={'height_ratios': [1,4], 'hspace': 0.})\n",
    "colors = ['blue', 'orange','green','red']\n",
    "linestyles = ['--', '-', '-.', ':']\n",
    "end = '_attn'\n",
    "\n",
    "extras = pickle.load(open('results/PSNR_attention_10k.pkl', 'rb'))\n",
    "\n",
    "ax[0,2].axis('off')\n",
    "for i, key in enumerate(['outer','inner','radial','tangential']):\n",
    "    acc = np.array([x[1] for x in extras[key+end]]).reshape(-1, 1)\n",
    "    ci = np.abs(np.array(extras['confidence_intervals'][key+end]) - acc).T\n",
    "    ax[1,2].errorbar(model.rf_to_image_space(layer_id, extras['extent'])[0] / 20.,\n",
    "                     acc, yerr=ci, color=colors[i], capsize=2., alpha=0.8,\n",
    "                     linestyle=linestyles[i])\n",
    "ax[1,2].set_ylabel('Accuracy (Proportion Correct)')\n",
    "ax[1,2].set_xlabel('Attentional Field Extent (DVA)')\n",
    "# ax[1,2].yaxis.grid(which='major', color='gray', alpha=0.8, linestyle='dashed', linewidth=1.)\n",
    "ax[1,2].legend(['Outer','Inner','Radial','Tangential'])\n",
    "fig.tight_layout()\n",
    "    \n",
    "extent_types = ['Min.', 'Max.']\n",
    "for i, extent in enumerate([7., 27.]):\n",
    "    im_extent = model.rf_to_image_space(layer_id, extent)[0]\n",
    "    priority_map = torch.zeros(118,118)\n",
    "    priority_map[59,59] = 1./im_extent\n",
    "    af = rf_pool.utils.lattice.gaussian_field(priority_map)\n",
    "    max_y = np.max(af.numpy()) + 0.1\n",
    "    \n",
    "    mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, 0.2, 0., n_rings=10, std=1., offset=offset)\n",
    "    model.layers[layer_id].forward_layer.pool.set(mu=mu, sigma=sigma)\n",
    "    model = apply_attention_field(model, layer_id, mu, sigma, [26,26], extent)\n",
    "    visualize.heatmap(model, layer_id, show=False)\n",
    "    \n",
    "    if i == 1:\n",
    "        af = af - np.min(af.numpy()) - 0.2\n",
    "    ax[0,i].plot(np.arange(118), af[0,:,59], 'black')\n",
    "    ax[0,i].axis('off')\n",
    "    ax[0,i].set_ylim(0., max_y)\n",
    "    \n",
    "    extent_dva = model.rf_to_image_space(layer_id, extent)[0] / 20.\n",
    "    ax[1,i].set_xlabel('%s Attentional Field Extent (%d DVA)' % (extent_types[i], extent_dva))\n",
    "    visualize.heatmap(model, layer_id, ax=ax[1,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/%s_acc.pdf' % task.lower(), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Density/Size Figures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'results/PSNR_density_10k.pkl'\n",
    "extras = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Density_Size'\n",
    "fig, ax = plt.subplots(1,2, figsize=(4.8, 2.4))\n",
    "colors = ['orange','black','blue']\n",
    "linestyles = ['-', '-', '--']\n",
    "end = ''\n",
    "\n",
    "# create figure with density plot\n",
    "for i, key in enumerate(['cost_0','cost_1','cost_2']):\n",
    "    snr = np.array([x[0] for x in extras[key+end]]).reshape(-1, 1)\n",
    "    ci = np.abs(np.array(extras['confidence_intervals'][key+end]) - snr).T\n",
    "    ax[0].errorbar(extras['spacing'], snr, yerr=ci, color=colors[i], capsize=2., alpha=0.8,\n",
    "                   linestyle=linestyles[i])\n",
    "ax[0].set_ylabel('Peak Signal-to-Noise Ratio (dB)')\n",
    "ax[0].set_xlabel('RF Spacing (Units of Sigma)')\n",
    "# ax[0].yaxis.grid(which='major', color='gray', alpha=0.8, linestyle='dashed', linewidth=1.)\n",
    "ax[0].legend(['$\\sigma$ = %0.2f' % (model.rf_to_image_space(layer_id, extras[k][0])[0] / 20.)\n",
    "              for k in ['sigma_0','sigma_1','sigma_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'results/PSNR_size_10k.pkl'\n",
    "extras = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add size plot\n",
    "key = 'cost_0'\n",
    "end = ''\n",
    "colors = ['black']\n",
    "\n",
    "for i, key in enumerate(['cost_0']):\n",
    "    snr = np.array([x[0] for x in extras[key+end][1:]]).reshape(-1, 1)\n",
    "    ci = np.abs(np.array(extras['confidence_intervals'][key+end][1:]) - snr).T\n",
    "    ax[1].errorbar(model.rf_to_image_space(layer_id, extras['sigma_0'][1:])[0] / 20.,\n",
    "                   snr, yerr=ci, color=colors[i], capsize=2., alpha=0.8)\n",
    "ax[1].set_ylabel('Peak Signal-to-Noise Ratio (dB)')\n",
    "ax[1].set_xlabel('RF Sigma Size (DVA)')\n",
    "# ax[1].yaxis.grid(which='major', color='gray', alpha=0.8, linestyle='dashed', linewidth=1.)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/%s_snr.pdf' % task.lower(), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MISC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(5., 2.8), gridspec_kw={'height_ratios': [1,4], 'hspace': 0.})\n",
    "\n",
    "for i, extent in enumerate([0., 10.]):\n",
    "    if extent > 0.:\n",
    "        im_extent = model.rf_to_image_space(layer_id, extent)[0]\n",
    "        priority_map = torch.zeros(118,118)\n",
    "        priority_map[59,59] = 1./im_extent\n",
    "        af = rf_pool.utils.lattice.gaussian_field(priority_map)\n",
    "    else:\n",
    "        af = torch.ones(1,118,118)\n",
    "\n",
    "    model = apply_attention_field(model, layer_id, mu, sigma, [26,26], extent)\n",
    "    idx = [33,51]\n",
    "    visualize.heatmap(model, layer_id, input=target_set[0][0][0], ax=ax[1,i],\n",
    "                      RF_linestyles=['dashed' if i in idx else 'solid' for i in range(n_kernels)],\n",
    "                      RF_alpha=1.,\n",
    "                      RF_linewidths=[1. if i in idx else 0.25 for i in range(n_kernels)],\n",
    "                      RF_edgecolors=['red' if i in idx else 'black' for i in range(n_kernels)])\n",
    "    \n",
    "    ax[0,i].plot(np.arange(118), af[0,:,59], 'black')\n",
    "    ax[0,i].axis('off')\n",
    "    ax[1,i].set_xlabel(['No Attention','Attention'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('figures/example_heatmap.pdf', bbox_inches='tight', dpi=600.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
