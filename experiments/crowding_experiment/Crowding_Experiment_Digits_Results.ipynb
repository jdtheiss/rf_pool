{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "import imp\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_pool import models, modules, pool, ops\n",
    "from rf_pool.utils import lattice, functions, visualize, datasets, stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['results', 'datasets']\n",
    "for d in directories:\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load MNIST Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='../../data', train=True, download=True, \n",
    "                                       transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='../../data', train=False, download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in crowded digits base set\n",
    "base_set_filename = 'MNIST_cross_CrowdedDataset.pkl'\n",
    "if os.path.exists('datasets/' + base_set_filename):\n",
    "    base_set = pickle.load(open('datasets/' + base_set_filename, 'rb'))\n",
    "else:\n",
    "    base_set = None\n",
    "    print('Base Set not found!')\n",
    "    \n",
    "# set what labels mmap to what digit\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = rf_pool.models.FeedForwardNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append layers of model\n",
    "model.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(1,32,5),\n",
    "                                              activation=torch.nn.ReLU(), \n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(32,64,5),\n",
    "                                              activation=torch.nn.ReLU(),\n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('2', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(64,10,4)))\n",
    "model.append('3', rf_pool.modules.FeedForward(input_shape=(-1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous model and results\n",
    "(_, extras) = model.load_model('models/MNIST_rate_0.2_10k_3deg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove reshape layer \n",
    "model.layers.pop('3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace max pool layer with rf pool layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the rf layer\n",
    "img_shape = torch.Size((53,53))\n",
    "offset = [0., -30.] # right visual field (3deg)\n",
    "ref_axis = 0. # set the reference axis for the crowding configurations\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, RF_rate, gap, n_rings=n_rings, std=std,\n",
    "                                                        offset=offset)\n",
    "rf_layer = rf_pool.pool.RF_Pool(mu=mu, sigma=sigma, img_shape=img_shape, \n",
    "                                lattice_fn=rf_pool.utils.lattice.mask_kernel_lattice,\n",
    "                                pool_fn='max_pool', kernel_size=2)\n",
    "n_kernels = rf_layer.mu.shape[0]\n",
    "# append the rf pool layer to the model\n",
    "layer_id = '1'\n",
    "model.layers[layer_id].forward_layer.add_module('pool', rf_layer)\n",
    "visualize.heatmap(model, '1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'accuracy'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]\n",
    "\n",
    "# set spacings, extents, configuration types\n",
    "spacings = [1.] #np.linspace(1., 2., 9)\n",
    "extents = np.arange(7.,29.5,2.5)\n",
    "crowd_types = ['cross'] #['inner', 'outer', 'radial', 'tangential']\n",
    "\n",
    "# set function\n",
    "fn = getattr(experiment_functions, 'get_%s' % exp_type.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the experiment\n",
    "output = {}\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    output_i = {}\n",
    "    for extent in extents:\n",
    "        for spacing in spacings:\n",
    "            # get target data\n",
    "            target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0,\n",
    "                                          base_set=base_set, label_map=label_map,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                                                        jitter_fn(5, 5, seed=0)]))\n",
    "            target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                        shuffle=False, num_workers=2)\n",
    "            # create square data set to get redundancy metric\n",
    "            s = stimuli.make_crowded_stimuli(torch.ones(20,20), [], 0., (118,118))\n",
    "            square_set = datasets.Dataset(data=[s], transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                          jitter_fn(5, 5, seed=0)]))\n",
    "            square_loader = torch.utils.data.DataLoader(square_set, batch_size=1, shuffle=False, num_workers=2)\n",
    "            # get crowding set (without target to account for flankers in get_contribution call)\n",
    "            crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, \n",
    "                                         base_set=base_set, label_map=label_map,\n",
    "                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                       jitter_fn(5, 5, seed=0)]))\n",
    "            crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "            # set lattice kwargs \n",
    "            lattice_fn = lattice.init_foveated_lattice\n",
    "            lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                              'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                              'rotate': rotate_fn(rot_angle / 2., base_angle=ref_axis, seed=0)}\n",
    "            # get output_i\n",
    "            output_i.update({'spacing_%a_extent_%a' % (spacing, extent): \n",
    "                             fn(target_loader, crowd_loader, #square_loader,\n",
    "                                **{'layer_id': layer_id,\n",
    "                                   'model': model,\n",
    "                                   'extent': extent,\n",
    "                                   'lattice_fn': lattice_fn,\n",
    "                                   'lattice_kwargs': lattice_kwargs})})\n",
    "            # monitor progress\n",
    "            clear_output(wait=True)\n",
    "            display('%s: spacing %a, extent %a' % (key, spacing, extent))\n",
    "    # update output\n",
    "    output.update({'%s_%s' % (key, exp_type.lower()): output_i, 'spacing': spacings, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get PCA of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'accuracy'\n",
    "n_test = 1000\n",
    "\n",
    "# set output, redundancy, fidelity\n",
    "output = pickle.load(open('results/%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'rb'))\n",
    "redundancy = pickle.load(open('results/redundancy_1k.pkl', 'rb'))\n",
    "fidelity = pickle.load(open('results/mse_1k.pkl', 'rb'))\n",
    "key = 'cross'\n",
    "output_key = '%s_%s' % (key, 'ACC') #exp_type.lower())\n",
    "fidelity_key = '%s_%s' % (key, 'MSE')\n",
    "redundancy_key = '%s_%s' % (key, 'redundancy')\n",
    "\n",
    "# set stat function\n",
    "stat_fn = lambda x: x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data array\n",
    "X = []\n",
    "for i, space in enumerate(output.get('spacing')):\n",
    "    for j, extent in enumerate(output.get('extent')):\n",
    "        X.append([fidelity.get(fidelity_key).get('spacing_%a_attn_None' % space).sum() / 5., \n",
    "                  redundancy.get(redundancy_key).get('spacing_%a_extent_%a' % (1., extent)), \n",
    "                  stat_fn(output.get(output_key).get('spacing_%a_extent_%a' % (space, extent)))])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scaler.inverse_transform([0., 0., 0.])\n",
    "e = scaler.inverse_transform(pca.components_[0])\n",
    "data = scaler.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig, azim=20.)\n",
    "ax.scatter(data[:,0], data[:,1], data[:,2])\n",
    "ax.plot([s[0], e[0]], [s[1], e[1]], [s[2], e[2]], color='red')\n",
    "plt.xlabel('Fidelity')\n",
    "plt.ylabel('Redundancy')\n",
    "ax.set_zlabel('Target Confidence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for i, x in enumerate(X):\n",
    "    y.append(x[-1])\n",
    "    X[i][-1] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LinearRegression(fit_intercept=False)\n",
    "clf.fit(X[:,2:], y)\n",
    "r2_inter = clf.score(X[:,2:], y)\n",
    "print('Intercept:', r2_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.LinearRegression(fit_intercept=False)\n",
    "clf.fit(X[:,1:], y)\n",
    "r2_attn = clf.score(X[:,1:], y) - r2_inter\n",
    "print('Redundancy:', r2_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LinearRegression(fit_intercept=False)\n",
    "clf.fit(X, y)\n",
    "r2_space = clf.score(X, y) - (r2_attn + r2_inter)\n",
    "print('Fidelity:', r2_space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
