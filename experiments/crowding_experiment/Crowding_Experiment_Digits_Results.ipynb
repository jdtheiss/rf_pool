{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "import imp\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_pool import models, modules, pool, ops\n",
    "from rf_pool.utils import lattice, functions, visualize, datasets, stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['results', 'datasets']\n",
    "for d in directories:\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load MNIST Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='../../data', train=True, download=True, \n",
    "                                       transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='../../data', train=False, download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in crowded digits base set\n",
    "base_set_filename = 'MNIST_CrowdedDataset.pkl'\n",
    "if os.path.exists('datasets/' + base_set_filename):\n",
    "    base_set = pickle.load(open('datasets/' + base_set_filename, 'rb'))\n",
    "else:\n",
    "    base_set = None\n",
    "    print('Base Set not found!')\n",
    "    \n",
    "# set what labels mmap to what digit\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = rf_pool.models.FeedForwardNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append layers of model\n",
    "model.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(1,32,5),\n",
    "                                              activation=torch.nn.ReLU(), \n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(32,64,5),\n",
    "                                              activation=torch.nn.ReLU(),\n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('2', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(64,10,4)))\n",
    "model.append('3', rf_pool.modules.FeedForward(input_shape=(-1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous model and results\n",
    "(_, extras) = model.load_model('models/MNIST_rate_0.2_10k_3deg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove reshape layer \n",
    "model.layers.pop('3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace max pool layer with rf pool layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the rf layer\n",
    "img_shape = torch.Size((53,53))\n",
    "offset = [0., -30.] # right visual field (3deg)\n",
    "ref_axis = 0. # set the reference axis for the crowding configurations\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, RF_rate, gap, n_rings=n_rings, std=std,\n",
    "                                                        offset=offset)\n",
    "rf_layer = rf_pool.pool.RF_Pool(mu=mu, sigma=sigma, img_shape=img_shape, \n",
    "                                lattice_fn=rf_pool.utils.lattice.mask_kernel_lattice,\n",
    "                                pool_fn='max_pool', kernel_size=2)\n",
    "n_kernels = rf_layer.mu.shape[0]\n",
    "# append the rf pool layer to the model\n",
    "layer_id = '1'\n",
    "model.layers[layer_id].forward_layer.add_module('pool', rf_layer)\n",
    "visualize.heatmap(model, '1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Attention'\n",
    "n_test = 100\n",
    "batch_size = 1\n",
    "# get target data\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map)\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = np.arange(7.,29.5,2.5)\n",
    "spacing = 1.\n",
    "crowd_types = ['radial','tangential', 'outer', 'inner']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "for key in crowd_types: \n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing,\n",
    "                                 base_set, label_map)\n",
    "    crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                               shuffle=False, num_workers=2)\n",
    "    param_space = extents\n",
    "    param_name = ['extent']\n",
    "    lattice_fn = lattice.init_foveated_lattice\n",
    "    lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                      'std': std, 'n_rings': n_rings, 'offset': offset, 'rotate': lambda : np.pi * np.random.rand()}\n",
    "    # Get accuracy\n",
    "    ACC = functions.param_search(get_accuracy, [target_loader, crowd_loader], \n",
    "                                 {'model':model,'batch_size': 1, 'layer_id':'1', 'extent': None,\n",
    "                                  'lattice_fn': lattice_fn, 'lattice_kwargs': lattice_kwargs},\n",
    "                                 param_name, param_space, verbose=False, show_cost=False)\n",
    "    RF_ACC.update({key + '_attn': ACC, 'extent': param_space})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Spacing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Spacing'\n",
    "n_test = 100\n",
    "batch_size = 1\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]\n",
    "\n",
    "# get target data\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                              transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spacings = np.arange(1., 2.25, 0.25)\n",
    "crowd_types = ['outer','inner','radial','tangential']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    ACC = []\n",
    "    for spacing in spacings:\n",
    "        clear_output(wait=True)\n",
    "        display('%s: %a' % (key, spacing))\n",
    "        crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                     transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "        crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                   shuffle=False, num_workers=2)\n",
    "        lattice_fn = lattice.init_foveated_lattice\n",
    "        lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                          'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                          'rotate': rotate_fn(rot_angle / 2., base_angle=0, seed=0)}\n",
    "        # Get accuracy\n",
    "        ACC.append(get_accuracy(target_loader, crowd_loader,\n",
    "                                **{'layer_id':'1', 'batch_size': batch_size, 'model':model,'extent': None, \n",
    "                                   'lattice_fn': lattice_fn,\n",
    "                                   'lattice_kwargs': lattice_kwargs}))\n",
    "    RF_ACC.update({key + '_space': ACC, 'spacing': np.arange(1., 2.25, 0.25)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Size/Position Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Attention_Size_Position'\n",
    "n_test = 100\n",
    "batch_size = 1\n",
    "# get target data\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map)\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = np.arange(7.,29.5,2.5)\n",
    "spacing = 1.\n",
    "crowd_types = ['radial','tangential', 'outer', 'inner']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "for key in crowd_types: \n",
    "    ACC = []\n",
    "    # set update_mu, update_sigma to True/False\n",
    "    for update_mu in [True, False]:\n",
    "        update_sigma = (not update_mu)\n",
    "        n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "        crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing,\n",
    "                                     base_set, label_map)\n",
    "        crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "        param_space = extents\n",
    "        param_name = ['extent']\n",
    "        lattice_fn = lattice.init_foveated_lattice\n",
    "        lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                          'std': std, 'n_rings': n_rings, 'offset': offset,\n",
    "                          'rotate': lambda : np.pi * np.random.rand()}\n",
    "        # Get accuracy\n",
    "        ACC.append(functions.param_search(get_accuracy, [target_loader, crowd_loader], \n",
    "                                          {'model': model, 'batch_size': 1, 'layer_id':'1', 'extent': None,\n",
    "                                           'lattice_fn': lattice_fn, 'lattice_kwargs': lattice_kwargs,\n",
    "                                           'update_mu': update_mu, 'update_sigma': update_sigma},\n",
    "                                          param_name, param_space, verbose=False, show_cost=False))\n",
    "    RF_ACC.update({key + '_attn': ACC, 'extent': param_space})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Heatmaps'\n",
    "n_test = 100\n",
    "batch_size = 1\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "# get target data\n",
    "target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                              transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                            shuffle=False, num_workers=2)\n",
    "# set rms function\n",
    "rms = lambda x: torch.sqrt(torch.mean(torch.pow(torch.tensor(x), 2.)))\n",
    "# get results\n",
    "results = pickle.load(open('ACC_spacing_10k.pkl', 'rb'))\n",
    "results.update(pickle.load(open('ACC_attention_10k.pkl', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacings = [1., 2.]\n",
    "extents = [None, 7., 27.]\n",
    "crowd_types = ['inner', 'outer', 'radial', 'tangential']\n",
    "# run the experiment\n",
    "RF_heatmaps = {}\n",
    "# get accuracy heatmaps\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    heatmap = []\n",
    "    for extent in extents:\n",
    "        for spacing in spacings:\n",
    "            # if extent and spacing > 1, skip\n",
    "            if extent is not None and spacing > 1.:\n",
    "                continue\n",
    "            # get crowding set (without target to account for flankers in get_contribution call)\n",
    "            crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                         no_target=True,\n",
    "                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                       jitter_fn(5, 5, seed=0)]))\n",
    "            crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "            # set lattice kwargs \n",
    "            lattice_fn = lattice.init_foveated_lattice\n",
    "            lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                              'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                              'rotate': rotate_fn(rot_angle / 2., base_angle=0, seed=0)}\n",
    "            # get heatmap\n",
    "            if extent is None:\n",
    "                result_name = key + '_space'\n",
    "                result_idx = np.where(results.get('spacing') == spacing)[0].item()\n",
    "            else:\n",
    "                result_name = key + '_attn'\n",
    "                result_idx = np.where(results.get('extent') == extent)[0].item()\n",
    "            # get rf scores\n",
    "            heatmap.append(get_contribution(target_loader, crowd_loader,\n",
    "                                            **{'layer_id':'1',\n",
    "                                               'model':model,\n",
    "                                               'RF_mask': None, \n",
    "                                               'acc': results[result_name][result_idx][-1],\n",
    "                                               'extent': extent,\n",
    "                                               'lattice_fn': lattice_fn,\n",
    "                                               'lattice_kwargs': lattice_kwargs}))\n",
    "            # monitor progress\n",
    "            clear_output(wait=True)\n",
    "            display('%s: spacing %a, extent %a' % (key, spacing, extent))\n",
    "            # plot heatmap\n",
    "            visualize.heatmap(model, '1', score_map=heatmap[-1], cmap='Greens', colorbar=True,\n",
    "                              filename='results/heatmap_%s_%s_%s.png' % (key, spacing, extent));\n",
    "    # append heatmaps\n",
    "    RF_heatmaps.update({key + '_heatmap': heatmap, 'spacing': spacings, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_heatmaps, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
