{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "import imp\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "from context import rf_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rf_pool import models, modules, pool, ops\n",
    "from rf_pool.utils import lattice, functions, visualize, datasets, stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_functions import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['results', 'datasets']\n",
    "for d in directories:\n",
    "    if not os.path.exists(d):\n",
    "        os.mkdir(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load MNIST Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MNIST training data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='../../data', train=True, download=True, \n",
    "                                       transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='../../data', train=False, download=True,\n",
    "                                     transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in crowded digits base set\n",
    "base_set_filename = 'MNIST_CrowdedDataset.pkl'\n",
    "if os.path.exists('datasets/' + base_set_filename):\n",
    "    base_set = pickle.load(open('datasets/' + base_set_filename, 'rb'))\n",
    "else:\n",
    "    base_set = None\n",
    "    print('Base Set not found!')\n",
    "    \n",
    "# set what labels mmap to what digit\n",
    "label_map = {}\n",
    "label_map.update([(n,n) for n in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model = rf_pool.models.FeedForwardNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append layers of model\n",
    "model.append('0', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(1,32,5),\n",
    "                                              activation=torch.nn.ReLU(), \n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('1', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(32,64,5),\n",
    "                                              activation=torch.nn.ReLU(),\n",
    "                                              pool=torch.nn.MaxPool2d(2)))\n",
    "model.append('2', rf_pool.modules.FeedForward(hidden=torch.nn.Conv2d(64,10,4)))\n",
    "model.append('3', rf_pool.modules.FeedForward(input_shape=(-1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous model and results\n",
    "(_, extras) = model.load_model('models/MNIST_rate_0.2_10k_3deg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove reshape layer \n",
    "model.layers.pop('3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace max pool layer with rf pool layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the rf layer\n",
    "img_shape = torch.Size((53,53))\n",
    "offset = [0., -30.] # right visual field (3deg)\n",
    "ref_axis = 0. # set the reference axis for the crowding configurations\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "mu, sigma = rf_pool.utils.lattice.init_foveated_lattice(img_shape, RF_rate, gap, n_rings=n_rings, std=std,\n",
    "                                                        offset=offset)\n",
    "rf_layer = rf_pool.pool.RF_Pool(mu=mu, sigma=sigma, img_shape=img_shape, \n",
    "                                lattice_fn=rf_pool.utils.lattice.mask_kernel_lattice,\n",
    "                                pool_fn='max_pool', kernel_size=2)\n",
    "n_kernels = rf_layer.mu.shape[0]\n",
    "# append the rf pool layer to the model\n",
    "layer_id = '1'\n",
    "model.layers[layer_id].forward_layer.add_module('pool', rf_layer)\n",
    "visualize.heatmap(model, '1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get redundancy as proportion overlap within target square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Attention'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = np.arange(7.,29.5,2.5)\n",
    "spacing = 1.\n",
    "crowd_types = ['outer','inner','radial','tangential']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    ACC = []\n",
    "    for extent in extents:\n",
    "        clear_output(wait=True)\n",
    "        display('%s: %a' % (key, extent))\n",
    "        # get target data\n",
    "        target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                                      transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "        target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                    shuffle=False, num_workers=2)\n",
    "        # get crowd data\n",
    "        crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                     transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "        crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                   shuffle=False, num_workers=2)\n",
    "        lattice_fn = lattice.init_foveated_lattice\n",
    "        lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                          'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                          'rotate': rotate_fn(rot_angle / 2., base_angle=ref_axis, seed=0)}\n",
    "        # Get accuracy\n",
    "        ACC.append(get_accuracy(target_loader, crowd_loader,\n",
    "                                **{'layer_id':'1', 'batch_size': batch_size, \n",
    "                                   'model': model, 'extent': extent, \n",
    "                                   'lattice_fn': lattice_fn,\n",
    "                                   'lattice_kwargs': lattice_kwargs}))\n",
    "    RF_ACC.update({key + '_attn': ACC, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Spacing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Spacing'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spacings = np.arange(1., 2.25, 0.25)\n",
    "crowd_types = ['outer','inner','radial','tangential']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    ACC = []\n",
    "    for spacing in spacings:\n",
    "        clear_output(wait=True)\n",
    "        display('%s: %a' % (key, spacing))\n",
    "        # get target data\n",
    "        target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                                      transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "        target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                    shuffle=False, num_workers=2)\n",
    "        # get crowd data\n",
    "        crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                     transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "        crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                   shuffle=False, num_workers=2)\n",
    "        lattice_fn = lattice.init_foveated_lattice\n",
    "        lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                          'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                          'rotate': rotate_fn(rot_angle / 2., base_angle=ref_axis, seed=0)}\n",
    "        # Get accuracy\n",
    "        ACC.append(get_accuracy(target_loader, crowd_loader,\n",
    "                                **{'layer_id':'1', 'batch_size': batch_size, \n",
    "                                   'model': model, 'extent': None, \n",
    "                                   'lattice_fn': lattice_fn,\n",
    "                                   'lattice_kwargs': lattice_kwargs}))\n",
    "    RF_ACC.update({key + '_space': ACC, 'spacing': spacings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Size/Position Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Attention_Size_Position'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extents = np.arange(7.,29.5,2.5)\n",
    "spacing = 1.\n",
    "crowd_types = ['radial','tangential', 'outer', 'inner']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "for key in crowd_types: \n",
    "    ACC = []\n",
    "    # set update_mu, update_sigma to True/False\n",
    "    for update_mu in [True, False]:\n",
    "        update_sigma = (not update_mu)\n",
    "        # get target data\n",
    "        target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map)\n",
    "        target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                    shuffle=False, num_workers=2)\n",
    "        # get crowd data\n",
    "        n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "        crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing,\n",
    "                                     base_set, label_map)\n",
    "        crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "        param_space = extents\n",
    "        param_name = ['extent']\n",
    "        lattice_fn = lattice.init_foveated_lattice\n",
    "        lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                          'std': std, 'n_rings': n_rings, 'offset': offset,\n",
    "                          'rotate': rotate_fn(rot_angle / 2., base_angle=ref_axis, seed=0)}\n",
    "        # Get accuracy\n",
    "        ACC.append(get_accuracy(target_loader, crowd_loader, \n",
    "                                **{'model': model, 'batch_size': 1, \n",
    "                                   'layer_id':'1', 'extent': extent,\n",
    "                                   'lattice_fn': lattice_fn, \n",
    "                                   'lattice_kwargs': lattice_kwargs,\n",
    "                                   'update_mu': update_mu, 'update_sigma': update_sigma}))\n",
    "        # monitor progress\n",
    "        clear_output(wait=True)\n",
    "        display('%s: mu %a, sigma %a' % (key, update_mu, update_sigma))\n",
    "    RF_ACC.update({key + '_attn': ACC, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/ACC_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment_functions\n",
    "imp.reload(experiment_functions)\n",
    "from experiment_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Heatmaps'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacings = np.arange(1., 2.25, 0.25)\n",
    "extents = [None] + np.arange(7.,29.5,2.5).tolist()\n",
    "crowd_types = ['inner', 'outer', 'radial', 'tangential']\n",
    "# run the experiment\n",
    "RF_heatmaps = {}\n",
    "# get accuracy heatmaps\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    heatmap = []\n",
    "    for extent in extents:\n",
    "        for spacing in spacings:\n",
    "            # if extent and spacing > 1, skip\n",
    "            if extent is not None and spacing > 1.:\n",
    "                continue\n",
    "            # get target data\n",
    "            target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "            target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                        shuffle=False, num_workers=2)\n",
    "            # get crowding set (without target to account for flankers in get_contribution call)\n",
    "            crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                         no_target=True,\n",
    "                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                       jitter_fn(5, 5, seed=0)]))\n",
    "            crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "            # set lattice kwargs \n",
    "            lattice_fn = lattice.init_foveated_lattice\n",
    "            lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                              'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                              'rotate': 0.}\n",
    "            # get rf scores\n",
    "            heatmap.append(get_confidence(target_loader, crowd_loader,\n",
    "                                            **{'layer_id': layer_id,\n",
    "                                               'model': model,\n",
    "                                               'RF_mask': None, \n",
    "                                               'acc': None,\n",
    "                                               'extent': extent,\n",
    "                                               'lattice_fn': lattice_fn,\n",
    "                                               'lattice_kwargs': lattice_kwargs}))\n",
    "            # monitor progress\n",
    "            clear_output(wait=True)\n",
    "            display('%s: spacing %a, extent %a' % (key, spacing, extent))\n",
    "    # append heatmaps\n",
    "    RF_heatmaps.update({key + '_heatmap': heatmap, 'spacing': spacings, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/confidence_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_heatmaps, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_heatmaps = pickle.load(open('results/confidence_heatmaps_1k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'tangential'\n",
    "exp_type = 'attention'\n",
    "s = len(RF_heatmaps['spacing']) * (exp_type == 'attention') + (exp_type == 'spacing')\n",
    "e = len(RF_heatmaps['spacing']) + (len(RF_heatmaps['extent']) - 1) * (exp_type == 'attention')\n",
    "m = len(RF_heatmaps['spacing']) - (exp_type == 'spacing')\n",
    "avg_heatmap = torch.mean(torch.stack(RF_heatmaps['%s_heatmap' % key][s:e]), 0)\n",
    "# max_heatmap = RF_heatmaps['%s_heatmap' % key][m]\n",
    "scores = avg_heatmap - RF_heatmaps['%s_heatmap' % key][0]\n",
    "for i, v in enumerate(scores):\n",
    "    if v == 0.:\n",
    "        scores[i] = np.nan\n",
    "fig = visualize.heatmap(model, layer_id, scores=scores, cmap='RdYlGn', colorbar=True, vmin=-0.1, vmax=0.1,\n",
    "                        figsize=(4.9,4.9))\n",
    "fig.suptitle('%s Avg - %s %s' % (key, ['Min', 'No'][exp_type=='attention'], exp_type))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_sums = {}\n",
    "keys = ['outer','inner','radial','tangential']\n",
    "colors = ['blue', 'orange','green','red']\n",
    "for i, key in enumerate(keys):\n",
    "    sums = []\n",
    "    confidence_sums.update({key: sums})\n",
    "    for ii in range(len(RF_heatmaps['spacing']), len(RF_heatmaps['%s_heatmap' % key])):\n",
    "        sums.append(np.sum([v for v in RF_heatmaps['%s_heatmap' % key][ii] if not torch.isnan(v)]))\n",
    "    plt.plot(RF_heatmaps['extent'][1:], sums, color=colors[i])\n",
    "plt.legend(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Average Area of FWHM Importance Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment_functions\n",
    "imp.reload(experiment_functions)\n",
    "from experiment_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'spread'\n",
    "n_test = 10000\n",
    "batch_size = 1\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacings = np.arange(1., 2.25, 0.25)\n",
    "extents = [None] + np.arange(7.,29.5,2.5).tolist()\n",
    "crowd_types = ['inner', 'outer', 'radial', 'tangential']\n",
    "# run the experiment\n",
    "importance_spread = {}\n",
    "# get accuracy heatmaps\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    spreads = []\n",
    "    for extent in extents:\n",
    "        for spacing in spacings:\n",
    "            # if extent and spacing > 1, skip\n",
    "            if extent is not None and spacing > 1.:\n",
    "                continue\n",
    "            # get target data\n",
    "            target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "            target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                        shuffle=False, num_workers=2)\n",
    "            # get flank set (without target to account for flankers in get_contribution call)\n",
    "            flank_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                         no_target=True,\n",
    "                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                       jitter_fn(5, 5, seed=0)]))\n",
    "            flank_loader = torch.utils.data.DataLoader(flank_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "            # set lattice kwargs \n",
    "            lattice_fn = lattice.init_foveated_lattice\n",
    "            lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                              'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                              'rotate': rotate_fn(rot_angle / 2., base_angle=ref_axis, seed=0)}\n",
    "            # get importance maps\n",
    "            maps_i = get_importance_map(target_loader, flank_loader,\n",
    "                                        **{'layer_id': layer_id,\n",
    "                                           'model': model,\n",
    "                                           'extent': extent,\n",
    "                                           'lattice_fn': lattice_fn,\n",
    "                                           'lattice_kwargs': lattice_kwargs})\n",
    "            # get average area FWHM\n",
    "            maps_i = torch.squeeze(torch.stack(maps_i))\n",
    "            fwhm = torch.max(torch.flatten(maps_i, -2), -1)[0] / 2.\n",
    "            spreads.append(torch.mean(torch.sum(torch.ge(maps_i, fwhm.reshape(-1, 1, 1)), [1,2]).float()))\n",
    "            # monitor progress\n",
    "            clear_output(wait=True)\n",
    "            display('%s: spacing %a, extent %a' % (key, spacing, extent))\n",
    "    # append heatmaps\n",
    "    importance_spread.update({key + '_spread': spreads, 'spacing': spacings, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/importance_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_heatmaps, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Redundancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment_functions\n",
    "imp.reload(experiment_functions)\n",
    "from experiment_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Redundancy'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacings = [1.]\n",
    "extents = np.arange(7.,29.5,2.5).tolist()\n",
    "crowd_types = ['']\n",
    "# run the experiment\n",
    "RF_redundancy = {}\n",
    "# get accuracy heatmaps\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    redundancy = []\n",
    "    for extent in extents:\n",
    "        for spacing in spacings:\n",
    "            # if extent and spacing > 1, skip\n",
    "            if extent is not None and spacing > 1.:\n",
    "                continue\n",
    "            # get target data\n",
    "            target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "            target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                        shuffle=False, num_workers=2)\n",
    "            # create square data set to get redundancy metric\n",
    "            s = stimuli.make_crowded_stimuli(torch.ones(20,20), [], 0., (118,118))\n",
    "            square_set = datasets.Dataset(data=[s], transform=transforms.Compose([transforms.ToTensor(), \n",
    "                                          jitter_fn(5, 5, seed=0)]))\n",
    "            square_loader = torch.utils.data.DataLoader(square_set, batch_size=1, shuffle=False, num_workers=2)\n",
    "            # get crowding set (without target to account for flankers in get_contribution call)\n",
    "            crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                         no_target=True,\n",
    "                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                       jitter_fn(5, 5, seed=0)]))\n",
    "            crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "            # set lattice kwargs \n",
    "            lattice_fn = lattice.init_foveated_lattice\n",
    "            lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                              'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                              'rotate': rotate_fn(rot_angle / 2., base_angle=0, seed=0)}\n",
    "            # get redundancy\n",
    "            redundancy.append(get_redundancy(target_loader, crowd_loader, square_loader,\n",
    "                                            **{'layer_id': layer_id,\n",
    "                                               'model': model,\n",
    "                                               'RF_mask': None, \n",
    "                                               'acc': None,\n",
    "                                               'extent': extent,\n",
    "                                               'lattice_fn': lattice_fn,\n",
    "                                               'lattice_kwargs': lattice_kwargs}))\n",
    "            # monitor progress\n",
    "            clear_output(wait=True)\n",
    "            display('%s: spacing %a, extent %a' % (key, spacing, extent))\n",
    "    # append heatmaps\n",
    "    RF_redundancy.update({key + 'redundancy': redundancy, 'spacing': spacings, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/RF_redundancy_10k.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_redundancy, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Correlation of Accuracy and Redundancy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pickle.load(open('results/ACC_attention_size_position_10k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_redundancy = pickle.load(open('results/RF_redundancy_10k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'inner'\n",
    "stats.pearsonr([v[0] for v in acc['%s_attn' % key][1]], RF_redundancy['redundancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'tangential'\n",
    "stats.pearsonr(confidence_sums['%s' % key], RF_redundancy['redundancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "reds = []\n",
    "for key in ['inner', 'outer', 'radial', 'tangential']:\n",
    "    accs.extend([v[0] for v in acc['%s_attn' % key][1]])\n",
    "    reds.extend(RF_redundancy['redundancy'])\n",
    "stats.pearsonr(accs, reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get accuracy for all conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment parameters\n",
    "exp_type = 'Accuracy'\n",
    "n_test = 1000\n",
    "batch_size = 1\n",
    "\n",
    "# set lattice kwargs\n",
    "img_shape = torch.Size((53,53))\n",
    "RF_rate = 0.2\n",
    "gap = 0.\n",
    "n_rings = 10\n",
    "std = 1.\n",
    "\n",
    "# get angle between RFs\n",
    "n_RF = np.floor(np.pi / RF_rate)\n",
    "angles = 2. * np.pi * np.linspace(0., 1., np.int(n_RF))[:-1]\n",
    "rot_angle = angles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacings = np.linspace(1., 2., 9).tolist()\n",
    "extents = np.arange(7.,29.5,2.5).tolist()\n",
    "crowd_types = ['inner', 'outer', 'radial', 'tangential']\n",
    "# run the experiment\n",
    "RF_ACC = {}\n",
    "# get accuracy heatmaps\n",
    "for key in crowd_types:\n",
    "    n_flankers, axis = get_crowd_params(key, ref_axis)\n",
    "    ACC = {}\n",
    "    for extent in extents:\n",
    "        for spacing in spacings:\n",
    "            # get target data\n",
    "            target_set = create_crowd_set(testset, n_test, 118, 0, 0, 0, base_set=base_set, label_map=label_map,\n",
    "                                          transform=transforms.Compose([transforms.ToTensor(), jitter_fn(5, 5, seed=0)]))\n",
    "            target_loader = torch.utils.data.DataLoader(target_set, batch_size=batch_size,\n",
    "                                                        shuffle=False, num_workers=2)\n",
    "            # get crowding set (without target to account for flankers in get_contribution call)\n",
    "            crowd_set = create_crowd_set(testset, n_test, 118, n_flankers, axis, spacing, base_set, label_map,\n",
    "                                         transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                       jitter_fn(5, 5, seed=0)]))\n",
    "            crowd_loader = torch.utils.data.DataLoader(crowd_set, batch_size=batch_size,\n",
    "                                                       shuffle=False, num_workers=2)\n",
    "            # set lattice kwargs \n",
    "            lattice_fn = lattice.init_foveated_lattice\n",
    "            lattice_kwargs = {'img_shape': img_shape, 'scale': RF_rate, 'spacing': gap, \n",
    "                              'std': std, 'n_rings': n_rings, 'offset': offset, \n",
    "                              'rotate': rotate_fn(rot_angle / 2., base_angle=ref_axis, seed=0)}\n",
    "            # get rf scores\n",
    "            ACC.update({'space_%d_attn_%d' % (spacing, extent): get_accuracy(target_loader, crowd_loader,\n",
    "                                                                            **{'layer_id': layer_id,\n",
    "                                                                               'model': model,\n",
    "                                                                               'RF_mask': None,\n",
    "                                                                               'extent': extent,\n",
    "                                                                               'lattice_fn': lattice_fn,\n",
    "                                                                               'lattice_kwargs': lattice_kwargs})})\n",
    "            # monitor progress\n",
    "            clear_output(wait=True)\n",
    "            display('%s: spacing %a, extent %a' % (key, spacing, extent))\n",
    "    # append heatmaps\n",
    "    RF_ACC.update({key + '_ACC': ACC, 'spacing': spacings, 'extent': extents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/RF_%s_%dk.pkl' % (exp_type.lower(), n_test/1000), 'wb') as f:\n",
    "    pickle.dump(RF_ACC, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
